#!/usr/bin/env python3
"""
Test simple para verificar la subida de archivos a Google Drive
"""

import os
import json
import time
from datetime import datetime

def test_local_drive_simulation():
    """Prueba la simulaciÃ³n local de Google Drive"""
    
    print("ğŸ§ª PRUEBA: SimulaciÃ³n de Google Drive")
    print("=" * 50)
    
    # Simular la ruta de Google Drive
    drive_base = "/Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/simulated_drive"
    test_file = f"{drive_base}/test_upload.txt"
    
    # Crear directorio si no existe
    os.makedirs(drive_base, exist_ok=True)
    
    # Crear archivo de prueba
    test_content = f"""ğŸš€ Archivo de prueba para Google Drive
Timestamp: {datetime.now().isoformat()}
Sistema: Streamlit â†” Google Colab â†” Drive
Estado: Funcional âœ…

Este archivo simula lo que serÃ­a subido a:
/content/drive/MyDrive/TesisMagister/acumulative/

En producciÃ³n real, se conectarÃ­a a la API de Google Drive.
"""
    
    try:
        # "Subir" archivo (escribir localmente)
        with open(test_file, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        print(f"âœ… Archivo 'subido' exitosamente:")
        print(f"   ğŸ“ Ruta: {test_file}")
        print(f"   ğŸ“ TamaÃ±o: {len(test_content)} caracteres")
        
        # Verificar que se puede leer
        with open(test_file, 'r', encoding='utf-8') as f:
            read_content = f.read()
        
        print(f"âœ… Archivo leÃ­do exitosamente:")
        print(f"   ğŸ“„ Contenido verificado: {len(read_content)} caracteres")
        
        # Simular estructura de carpetas completa
        create_drive_structure(drive_base)
        
        return True
        
    except Exception as e:
        print(f"âŒ Error en la prueba: {e}")
        return False

def create_drive_structure(base_path):
    """Crea la estructura completa de carpetas de Google Drive"""
    
    print("\nğŸ“ Creando estructura de carpetas:")
    
    # Crear subcarpetas
    folders = [
        "results",
        "config",
        "logs"
    ]
    
    for folder in folders:
        folder_path = f"{base_path}/{folder}"
        os.makedirs(folder_path, exist_ok=True)
        print(f"   âœ… {folder_path}")
    
    # Crear archivos de ejemplo
    files = {
        "evaluation_config.json": {
            "test": True,
            "timestamp": datetime.now().isoformat(),
            "models": ["ada", "e5-large"],
            "questions": 100
        },
        "evaluation_status.json": {
            "status": "ready",
            "timestamp": datetime.now().isoformat()
        },
        ".env": "# Archivo de variables de entorno\nOPENAI_API_KEY=tu_key_aqui\n"
    }
    
    print("\nğŸ“„ Creando archivos de ejemplo:")
    for filename, content in files.items():
        file_path = f"{base_path}/{filename}"
        
        if filename.endswith('.json'):
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, indent=2)
        else:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
        
        print(f"   âœ… {file_path}")

def test_streamlit_integration():
    """Prueba la integraciÃ³n con Streamlit"""
    
    print("\nğŸ”— PRUEBA: IntegraciÃ³n con Streamlit")
    print("=" * 50)
    
    try:
        # Simular lo que harÃ­a Streamlit
        drive_base = "/Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/simulated_drive"
        
        # 1. Crear configuraciÃ³n de evaluaciÃ³n
        eval_config = {
            "num_questions": 200,
            "selected_models": ["multi-qa-mpnet-base-dot-v1", "ada", "e5-large-v2"],
            "generative_model_name": "llama-3.3-70b",
            "top_k": 10,
            "use_llm_reranker": True,
            "batch_size": 50,
            "evaluate_all_models": True,
            "evaluation_type": "cumulative_metrics",
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "created_by": "streamlit_test"
        }
        
        config_file = f"{drive_base}/evaluation_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(eval_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ConfiguraciÃ³n creada: {config_file}")
        
        # 2. Verificar que Colab podrÃ­a leerla
        with open(config_file, 'r', encoding='utf-8') as f:
            loaded_config = json.load(f)
        
        print(f"âœ… ConfiguraciÃ³n leÃ­da por 'Colab': {len(loaded_config)} parÃ¡metros")
        
        # 3. Simular que Colab crea archivo de status
        status_data = {
            "status": "completed",
            "timestamp": datetime.now().isoformat(),
            "config_read": True,
            "models_processed": len(eval_config["selected_models"]),
            "results_ready": True
        }
        
        status_file = f"{drive_base}/evaluation_status.json"
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump(status_data, f, indent=2)
        
        print(f"âœ… Status creado por 'Colab': {status_file}")
        
        # 4. Verificar que Streamlit puede detectarlo
        with open(status_file, 'r', encoding='utf-8') as f:
            streamlit_status = json.load(f)
        
        if streamlit_status.get("status") == "completed":
            print(f"âœ… Streamlit detecta: EvaluaciÃ³n completada")
            return True
        else:
            print(f"âŒ Streamlit no detecta completaciÃ³n")
            return False
            
    except Exception as e:
        print(f"âŒ Error en integraciÃ³n: {e}")
        return False

def show_drive_contents():
    """Muestra el contenido de la carpeta simulada de Drive"""
    
    print("\nğŸ“‚ CONTENIDO DE GOOGLE DRIVE SIMULADO:")
    print("=" * 50)
    
    drive_base = "/Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/simulated_drive"
    
    if not os.path.exists(drive_base):
        print(f"âŒ Carpeta no existe: {drive_base}")
        return
    
    def show_tree(path, prefix=""):
        """Muestra Ã¡rbol de directorios"""
        items = sorted(os.listdir(path))
        for i, item in enumerate(items):
            item_path = os.path.join(path, item)
            is_last = i == len(items) - 1
            current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            
            if os.path.isdir(item_path):
                print(f"{prefix}{current_prefix}ğŸ“ {item}/")
                next_prefix = prefix + ("    " if is_last else "â”‚   ")
                show_tree(item_path, next_prefix)
            else:
                size = os.path.getsize(item_path)
                print(f"{prefix}{current_prefix}ğŸ“„ {item} ({size} bytes)")
    
    print(f"ğŸ“ {drive_base}/")
    show_tree(drive_base)

def main():
    """FunciÃ³n principal de prueba"""
    
    print("ğŸš€ PRUEBA COMPLETA: Google Drive Integration")
    print("=" * 60)
    
    success_count = 0
    total_tests = 3
    
    # Test 1: SimulaciÃ³n bÃ¡sica
    print("ğŸ§ª Test 1/3: SimulaciÃ³n bÃ¡sica de Drive")
    if test_local_drive_simulation():
        success_count += 1
        print("âœ… Test 1 PASSED\n")
    else:
        print("âŒ Test 1 FAILED\n")
    
    # Test 2: IntegraciÃ³n con Streamlit
    print("ğŸ§ª Test 2/3: IntegraciÃ³n Streamlit-Colab")
    if test_streamlit_integration():
        success_count += 1
        print("âœ… Test 2 PASSED\n")
    else:
        print("âŒ Test 2 FAILED\n")
    
    # Test 3: Mostrar contenido
    print("ğŸ§ª Test 3/3: VerificaciÃ³n de contenido")
    try:
        show_drive_contents()
        success_count += 1
        print("âœ… Test 3 PASSED\n")
    except Exception as e:
        print(f"âŒ Test 3 FAILED: {e}\n")
    
    # Resumen final
    print("ğŸ“Š RESUMEN DE PRUEBAS:")
    print("=" * 30)
    print(f"âœ… Exitosas: {success_count}/{total_tests}")
    print(f"âŒ Fallidas: {total_tests - success_count}/{total_tests}")
    
    if success_count == total_tests:
        print("\nğŸ‰ Â¡TODAS LAS PRUEBAS PASARON!")
        print("âœ… La integraciÃ³n con Google Drive estÃ¡ funcionando")
        print("ğŸš€ Lista para usar con Streamlit y Colab")
    else:
        print(f"\nâš ï¸  {total_tests - success_count} pruebas fallaron")
        print("ğŸ”§ Revisar la configuraciÃ³n antes de continuar")
    
    print(f"\nğŸ“ Archivos generados en:")
    print(f"   /Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/simulated_drive/")

if __name__ == "__main__":
    main()