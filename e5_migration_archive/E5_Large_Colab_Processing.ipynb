{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Guardar resultados comparativos finales\nif COMPARISON_ENABLED and ada_embeddings is not None:\n    print(\"üíæ Guardando resultados comparativos...\")\n    \n    # Compilar todos los resultados\n    comparison_results = {\n        'metadata': {\n            'timestamp': datetime.now().isoformat(),\n            'ada_model': 'text-embedding-ada-002',\n            'e5_model': 'intfloat/e5-large-v2',\n            'total_documents_compared': len(ada_embeddings),\n            'colab_gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n            'analysis_sample_size': similarity_metrics['sample_size']\n        },\n        'ada_properties': ada_properties,\n        'e5_properties': e5_properties,\n        'similarity_metrics': similarity_metrics,\n        'interpretation': {\n            'concordance_level': 'alta' if similarity_metrics['cosine_similarity_mean'] > 0.8 else \n                               'moderada' if similarity_metrics['cosine_similarity_mean'] > 0.6 else 'baja',\n            'correlation_strength': 'fuerte' if similarity_metrics['pearson_correlation'] > 0.7 else\n                                  'moderada' if similarity_metrics['pearson_correlation'] > 0.4 else 'd√©bil',\n            'recommendation': 'Los modelos muestran comportamiento similar' if similarity_metrics['cosine_similarity_mean'] > 0.7 \n                            else 'Los modelos capturan aspectos diferentes del texto'\n        }\n    }\n    \n    # Guardar resultados comparativos\n    comparison_file = f\"{DRIVE_BASE}/ada_vs_e5_comparison_results.json\"\n    with open(comparison_file, 'w', encoding='utf-8') as f:\n        json.dump(comparison_results, f, ensure_ascii=False, indent=2)\n    \n    print(f\"‚úÖ Resultados comparativos guardados en: {comparison_file}\")\n    \n    # Resumen ejecutivo\n    print(f\"\\nüìã RESUMEN EJECUTIVO:\")\n    print(\"=\" * 50)\n    print(f\"üéØ Concordancia entre modelos: {comparison_results['interpretation']['concordance_level'].upper()}\")\n    print(f\"üîó Correlaci√≥n: {comparison_results['interpretation']['correlation_strength'].upper()}\")\n    print(f\"üí° Recomendaci√≥n: {comparison_results['interpretation']['recommendation']}\")\n    \n    print(f\"\\nüìä M√©tricas clave:\")\n    print(f\"   ‚Ä¢ Similitud coseno promedio: {similarity_metrics['cosine_similarity_mean']:.4f}\")\n    print(f\"   ‚Ä¢ Correlaci√≥n Pearson: {similarity_metrics['pearson_correlation']:.4f}\")\n    print(f\"   ‚Ä¢ Correlaci√≥n matrices similitud: {similarity_metrics['similarity_matrix_correlation']:.4f}\")\n    \n    print(f\"\\nüíæ Archivos generados para descarga:\")\n    print(f\"   ‚Ä¢ {json_output} (embeddings E5)\")\n    print(f\"   ‚Ä¢ {comparison_file} (an√°lisis comparativo)\")\n    if 'viz_path' in locals():\n        print(f\"   ‚Ä¢ {viz_path} (visualizaciones)\")\n    \n    print(f\"\\nüéâ ¬°An√°lisis comparativo completado exitosamente!\")\n    \nelse:\n    print(\"üìù Resultados comparativos no generados (comparaci√≥n no habilitada)\")\n    print(\"üí° Para generar comparaci√≥n, sube un archivo con embeddings Ada-002\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generar visualizaciones comparativas (opcional)\nif COMPARISON_ENABLED and ada_embeddings is not None:\n    try:\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        \n        print(\"üìä Generando visualizaciones...\")\n        \n        # Configurar estilo\n        plt.style.use('default')\n        sns.set_palette(\"husl\")\n        \n        # Crear figura con subplots\n        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n        fig.suptitle('Comparaci√≥n Ada-002 vs E5-Large-v2', fontsize=16, fontweight='bold')\n        \n        # 1. Distribuci√≥n de normas\n        ada_norms = np.linalg.norm(ada_embeddings, axis=1)\n        e5_norms = np.linalg.norm(e5_embeddings, axis=1)\n        \n        axes[0,0].hist(ada_norms, bins=50, alpha=0.7, label='Ada-002', density=True)\n        axes[0,0].hist(e5_norms, bins=50, alpha=0.7, label='E5-Large-v2', density=True)\n        axes[0,0].set_title('Distribuci√≥n de Normas de Embeddings')\n        axes[0,0].set_xlabel('Norma L2')\n        axes[0,0].set_ylabel('Densidad')\n        axes[0,0].legend()\n        axes[0,0].grid(True, alpha=0.3)\n        \n        # 2. Similitud coseno por documento\n        cos_sims = similarity_metrics['cosine_similarity_mean']\n        sample_indices = np.random.choice(len(ada_embeddings), min(500, len(ada_embeddings)), replace=False)\n        sample_cos_sims = []\n        \n        for i in sample_indices:\n            ada_norm = ada_embeddings[i] / np.linalg.norm(ada_embeddings[i])\n            e5_norm = e5_embeddings[i] / np.linalg.norm(e5_embeddings[i])\n            cos_sim = np.dot(ada_norm, e5_norm)\n            sample_cos_sims.append(cos_sim)\n        \n        axes[0,1].hist(sample_cos_sims, bins=30, alpha=0.7, color='green')\n        axes[0,1].axvline(np.mean(sample_cos_sims), color='red', linestyle='--', \n                         label=f'Media: {np.mean(sample_cos_sims):.3f}')\n        axes[0,1].set_title('Distribuci√≥n de Similitud Coseno')\n        axes[0,1].set_xlabel('Similitud Coseno')\n        axes[0,1].set_ylabel('Frecuencia')\n        axes[0,1].legend()\n        axes[0,1].grid(True, alpha=0.3)\n        \n        # 3. Comparaci√≥n de dimensiones (muestra)\n        sample_dims = min(20, ada_embeddings.shape[1])\n        dim_indices = np.random.choice(ada_embeddings.shape[1], sample_dims, replace=False)\n        \n        ada_means = [np.mean(ada_embeddings[:, dim]) for dim in dim_indices]\n        e5_means = [np.mean(e5_embeddings[:, dim]) for dim in dim_indices]\n        \n        axes[1,0].scatter(ada_means, e5_means, alpha=0.6)\n        axes[1,0].plot([min(ada_means + e5_means), max(ada_means + e5_means)], \n                      [min(ada_means + e5_means), max(ada_means + e5_means)], \n                      'r--', alpha=0.8, label='y=x')\n        axes[1,0].set_title('Correlaci√≥n de Medias por Dimensi√≥n')\n        axes[1,0].set_xlabel('Media Ada-002')\n        axes[1,0].set_ylabel('Media E5-Large-v2')\n        axes[1,0].legend()\n        axes[1,0].grid(True, alpha=0.3)\n        \n        # 4. Matriz de correlaci√≥n de m√©tricas\n        metrics_data = {\n            'Ada Norma Media': [ada_properties['mean_norm']],\n            'E5 Norma Media': [e5_properties['mean_norm']],\n            'Similitud Coseno': [similarity_metrics['cosine_similarity_mean']],\n            'Correlaci√≥n Pearson': [similarity_metrics['pearson_correlation']],\n            'Correlaci√≥n Spearman': [similarity_metrics['spearman_correlation']],\n            'Similitud Centroides': [similarity_metrics['centroid_similarity']]\n        }\n        \n        # Crear tabla de resumen\n        axes[1,1].axis('tight')\n        axes[1,1].axis('off')\n        \n        table_data = [\n            ['M√©trica', 'Ada-002', 'E5-Large-v2'],\n            ['Dimensiones', f\"{ada_properties['dimensions']}\", f\"{e5_properties['dimensions']}\"],\n            ['Norma Media', f\"{ada_properties['mean_norm']:.4f}\", f\"{e5_properties['mean_norm']:.4f}\"],\n            ['Valor Medio', f\"{ada_properties['mean_value']:.6f}\", f\"{e5_properties['mean_value']:.6f}\"],\n            ['Desv. Est√°ndar', f\"{ada_properties['std_value']:.6f}\", f\"{e5_properties['std_value']:.6f}\"],\n            ['Sparsity (%)', f\"{ada_properties['sparsity']*100:.2f}\", f\"{e5_properties['sparsity']*100:.2f}\"],\n            ['', '', ''],\n            ['Similitud Coseno', f\"{similarity_metrics['cosine_similarity_mean']:.4f}\", '¬±' + f\"{similarity_metrics['cosine_similarity_std']:.4f}\"],\n            ['Correlaci√≥n Pearson', f\"{similarity_metrics['pearson_correlation']:.4f}\", ''],\n            ['Correlaci√≥n Spearman', f\"{similarity_metrics['spearman_correlation']:.4f}\", ''],\n            ['Similitud Centroides', f\"{similarity_metrics['centroid_similarity']:.4f}\", '']\n        ]\n        \n        table = axes[1,1].table(cellText=table_data, cellLoc='center', loc='center')\n        table.auto_set_font_size(False)\n        table.set_fontsize(9)\n        table.scale(1.2, 1.5)\n        \n        # Colorear encabezados\n        for i in range(len(table_data[0])):\n            table[(0, i)].set_facecolor('#E8E8E8')\n            table[(0, i)].set_text_props(weight='bold')\n        \n        axes[1,1].set_title('Resumen de M√©tricas Comparativas')\n        \n        plt.tight_layout()\n        \n        # Guardar visualizaci√≥n\n        viz_path = f\"{DRIVE_BASE}/comparison_visualization.png\"\n        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        print(f\"‚úÖ Visualizaci√≥n guardada en: {viz_path}\")\n        \n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Error generando visualizaciones: {e}\")\n        print(\"üí° Las visualizaciones son opcionales, el an√°lisis num√©rico se complet√≥ correctamente\")\n        \nelse:\n    print(\"‚è≠Ô∏è  Visualizaciones omitidas (comparaci√≥n no habilitada)\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Ejecutar an√°lisis comparativo\nif COMPARISON_ENABLED and ada_embeddings is not None:\n    print(\"üöÄ Iniciando an√°lisis comparativo Ada-002 vs E5-Large-v2...\")\n    \n    # Preparar embeddings E5 para comparaci√≥n\n    e5_embeddings = np.array([r['embedding'] for r in results_subset])\n    \n    print(f\"üìä Configuraci√≥n del an√°lisis:\")\n    print(f\"   Ada-002: {ada_embeddings.shape}\")\n    print(f\"   E5-Large-v2: {e5_embeddings.shape}\")\n    \n    # An√°lisis de propiedades individuales\n    ada_properties = analyze_embedding_properties(ada_embeddings, \"Ada-002\")\n    e5_properties = analyze_embedding_properties(e5_embeddings, \"E5-Large-v2\")\n    \n    # M√©tricas de similitud entre modelos\n    similarity_metrics = calculate_similarity_metrics(ada_embeddings, e5_embeddings)\n    \n    print(\"\\nüìà Resultados del an√°lisis:\")\n    print(\"=\" * 50)\n    \n    # Propiedades comparativas\n    print(f\"üìä PROPIEDADES DE EMBEDDINGS:\")\n    print(f\"{'M√©trica':<25} {'Ada-002':<15} {'E5-Large-v2':<15}\")\n    print(\"-\" * 55)\n    print(f\"{'Dimensiones':<25} {ada_properties['dimensions']:<15} {e5_properties['dimensions']:<15}\")\n    print(f\"{'Norma promedio':<25} {ada_properties['mean_norm']:<15.4f} {e5_properties['mean_norm']:<15.4f}\")\n    print(f\"{'Valor promedio':<25} {ada_properties['mean_value']:<15.6f} {e5_properties['mean_value']:<15.6f}\")\n    print(f\"{'Desv. est√°ndar':<25} {ada_properties['std_value']:<15.6f} {e5_properties['std_value']:<15.6f}\")\n    print(f\"{'Rango min-max':<25} [{ada_properties['min_value']:.3f}, {ada_properties['max_value']:.3f}] [{e5_properties['min_value']:.3f}, {e5_properties['max_value']:.3f}]\\\")\"})\n    print(f\"{'Sparsity (%)':<25} {ada_properties['sparsity']*100:<15.2f} {e5_properties['sparsity']*100:<15.2f}\")\n    print(f\"{'Memoria (MB)':<25} {ada_properties['memory_mb']:<15.1f} {e5_properties['memory_mb']:<15.1f}\")\n    \n    print(f\"\\nüîó SIMILITUD ENTRE MODELOS:\")\n    print(\"-\" * 40)\n    print(f\"Similitud coseno promedio: {similarity_metrics['cosine_similarity_mean']:.4f} ¬± {similarity_metrics['cosine_similarity_std']:.4f}\")\n    print(f\"Rango similitud coseno: [{similarity_metrics['cosine_similarity_min']:.4f}, {similarity_metrics['cosine_similarity_max']:.4f}]\")\n    print(f\"Correlaci√≥n Pearson: {similarity_metrics['pearson_correlation']:.4f}\")\n    print(f\"Correlaci√≥n Spearman: {similarity_metrics['spearman_correlation']:.4f}\")\n    print(f\"Similitud centroides: {similarity_metrics['centroid_similarity']:.4f}\")\n    print(f\"Correlaci√≥n matrices similitud: {similarity_metrics['similarity_matrix_correlation']:.4f}\")\n    \n    # Interpretaci√≥n de resultados\n    print(f\"\\nüí° INTERPRETACI√ìN:\")\n    print(\"-\" * 20)\n    cos_sim_mean = similarity_metrics['cosine_similarity_mean']\n    if cos_sim_mean > 0.8:\n        print(\"‚úÖ Alta concordancia entre modelos (similitud > 0.8)\")\n    elif cos_sim_mean > 0.6:\n        print(\"‚ö†Ô∏è  Concordancia moderada entre modelos (similitud 0.6-0.8)\")\n    else:\n        print(\"‚ùå Baja concordancia entre modelos (similitud < 0.6)\")\n    \n    pearson_corr = similarity_metrics['pearson_correlation']\n    if pearson_corr > 0.7:\n        print(\"‚úÖ Fuerte correlaci√≥n lineal entre espacios de embeddings\")\n    elif pearson_corr > 0.4:\n        print(\"‚ö†Ô∏è  Correlaci√≥n moderada entre espacios de embeddings\")\n    else:\n        print(\"‚ùå Correlaci√≥n d√©bil entre espacios de embeddings\")\n        \nelse:\n    print(\"‚è≠Ô∏è  An√°lisis comparativo omitido (no habilitado o sin datos Ada-002)\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Instalar dependencias adicionales para comparaci√≥n\nif COMPARISON_ENABLED:\n    !pip install scikit-learn scipy matplotlib seaborn",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Funciones de comparaci√≥n y m√©tricas\ndef calculate_similarity_metrics(embeddings1, embeddings2, sample_size=1000):\n    \"\"\"Calcular m√©tricas de similitud entre dos conjuntos de embeddings\"\"\"\n    from sklearn.metrics.pairwise import cosine_similarity\n    from scipy.stats import pearsonr, spearmanr\n    \n    print(f\"üî¨ Calculando m√©tricas de similitud...\")\n    \n    # Usar muestra si el dataset es muy grande\n    if len(embeddings1) > sample_size:\n        indices = np.random.choice(len(embeddings1), sample_size, replace=False)\n        emb1_sample = embeddings1[indices]\n        emb2_sample = embeddings2[indices]\n        print(f\"üìä Usando muestra de {sample_size:,} documentos para m√©tricas\")\n    else:\n        emb1_sample = embeddings1\n        emb2_sample = embeddings2\n        print(f\"üìä Usando todos los {len(embeddings1):,} documentos\")\n    \n    # Normalizar embeddings\n    from sklearn.preprocessing import normalize\n    emb1_norm = normalize(emb1_sample, norm='l2')\n    emb2_norm = normalize(emb2_sample, norm='l2')\n    \n    # Similitud coseno promedio entre embeddings correspondientes\n    cos_similarities = []\n    for i in range(len(emb1_norm)):\n        cos_sim = np.dot(emb1_norm[i], emb2_norm[i])\n        cos_similarities.append(cos_sim)\n    \n    cos_similarities = np.array(cos_similarities)\n    \n    # Correlaciones\n    # Flatten embeddings para correlaci√≥n global\n    emb1_flat = emb1_sample.flatten()\n    emb2_flat = emb2_sample.flatten()\n    \n    pearson_corr, _ = pearsonr(emb1_flat, emb2_flat)\n    spearman_corr, _ = spearmanr(emb1_flat, emb2_flat)\n    \n    # Similitud centroide\n    centroid1 = np.mean(emb1_norm, axis=0)\n    centroid2 = np.mean(emb2_norm, axis=0)\n    centroid_similarity = np.dot(centroid1, centroid2)\n    \n    # Matriz de similitud inter-modelo (muestra peque√±a)\n    sample_indices = np.random.choice(len(emb1_norm), min(100, len(emb1_norm)), replace=False)\n    sim_matrix_ada = cosine_similarity(emb1_norm[sample_indices])\n    sim_matrix_e5 = cosine_similarity(emb2_norm[sample_indices])\n    \n    # Correlaci√≥n de matrices de similitud\n    matrix_correlation, _ = pearsonr(sim_matrix_ada.flatten(), sim_matrix_e5.flatten())\n    \n    return {\n        'cosine_similarity_mean': float(np.mean(cos_similarities)),\n        'cosine_similarity_std': float(np.std(cos_similarities)),\n        'cosine_similarity_min': float(np.min(cos_similarities)),\n        'cosine_similarity_max': float(np.max(cos_similarities)),\n        'pearson_correlation': float(pearson_corr),\n        'spearman_correlation': float(spearman_corr),\n        'centroid_similarity': float(centroid_similarity),\n        'similarity_matrix_correlation': float(matrix_correlation),\n        'sample_size': len(emb1_sample)\n    }\n\ndef analyze_embedding_properties(embeddings, name):\n    \"\"\"Analizar propiedades de un conjunto de embeddings\"\"\"\n    print(f\"üîç Analizando propiedades de {name}...\")\n    \n    # Estad√≠sticas b√°sicas\n    emb_array = np.array(embeddings)\n    \n    properties = {\n        'model_name': name,\n        'total_documents': len(emb_array),\n        'dimensions': emb_array.shape[1],\n        'mean_norm': float(np.mean(np.linalg.norm(emb_array, axis=1))),\n        'std_norm': float(np.std(np.linalg.norm(emb_array, axis=1))),\n        'mean_value': float(np.mean(emb_array)),\n        'std_value': float(np.std(emb_array)),\n        'min_value': float(np.min(emb_array)),\n        'max_value': float(np.max(emb_array)),\n        'sparsity': float(np.mean(emb_array == 0.0)),\n        'memory_mb': float(emb_array.nbytes / 1024 / 1024)\n    }\n    \n    # An√°lisis de distribuci√≥n por dimensi√≥n (muestra)\n    sample_dims = min(10, emb_array.shape[1])\n    dim_stats = []\n    for i in range(sample_dims):\n        dim_values = emb_array[:, i]\n        dim_stats.append({\n            'dimension': i,\n            'mean': float(np.mean(dim_values)),\n            'std': float(np.std(dim_values)),\n            'min': float(np.min(dim_values)),\n            'max': float(np.max(dim_values))\n        })\n    \n    properties['dimension_sample_stats'] = dim_stats\n    \n    return properties\n\nprint(\"‚úÖ Funciones de comparaci√≥n definidas\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cargar embeddings Ada-002 para comparaci√≥n\nada_embeddings = None\nada_documents = None\n\nif COMPARISON_ENABLED:\n    try:\n        print(\"üì• Cargando embeddings Ada-002...\")\n        with open(ADA_EMBEDDINGS_FILE, 'r', encoding='utf-8') as f:\n            ada_data = json.load(f)\n        \n        ada_embeddings = np.array(ada_data['embeddings'])\n        ada_documents = ada_data['documents']\n        \n        print(f\"‚úÖ Cargados {len(ada_embeddings):,} embeddings Ada-002\")\n        print(f\"   Dimensiones Ada: {ada_embeddings.shape[1]}\")\n        print(f\"   Documentos: {len(ada_documents):,}\")\n        \n        # Verificar que coincidan los documentos\n        if len(ada_documents) != len(results):\n            print(f\"‚ö†Ô∏è  N√∫mero de documentos diferentes:\")\n            print(f\"   Ada: {len(ada_documents):,}\")\n            print(f\"   E5: {len(results):,}\")\n            print(\"üí° Se usar√° el conjunto com√∫n para comparaci√≥n\")\n            \n            min_docs = min(len(ada_documents), len(results))\n            ada_embeddings = ada_embeddings[:min_docs]\n            ada_documents = ada_documents[:min_docs]\n            results_subset = results[:min_docs]\n        else:\n            results_subset = results\n            \n        print(f\"üìä Conjunto final para comparaci√≥n: {len(ada_embeddings):,} documentos\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error cargando embeddings Ada: {e}\")\n        COMPARISON_ENABLED = False",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Configuraci√≥n para comparaci√≥n\nCOMPARISON_ENABLED = True  # Cambiar a False si no quieres comparar\nADA_EMBEDDINGS_FILE = f\"{DRIVE_BASE}/ada_embeddings.json\"  # Archivo con embeddings Ada-002\n\nprint(f\"üîç Comparaci√≥n de modelos: {'Habilitada' if COMPARISON_ENABLED else 'Deshabilitada'}\")\n\nif COMPARISON_ENABLED:\n    print(f\"üìÇ Buscando embeddings Ada-002 en: {ADA_EMBEDDINGS_FILE}\")\n    \n    try:\n        import os\n        if os.path.exists(ADA_EMBEDDINGS_FILE):\n            print(\"‚úÖ Archivo de embeddings Ada-002 encontrado\")\n        else:\n            print(\"‚ö†Ô∏è  Archivo de embeddings Ada-002 no encontrado\")\n            print(\"üí° Para habilitar comparaci√≥n, sube un archivo con embeddings Ada-002\")\n            COMPARISON_ENABLED = False\n    except Exception as e:\n        print(f\"‚ùå Error verificando archivo Ada: {e}\")\n        COMPARISON_ENABLED = False",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "# E5-Large-v2 GPU Embedding Generation\n",
    "\n",
    "Este notebook procesa documentos con E5-Large-v2 usando GPU de Colab para m√°xima velocidad.\n",
    "\n",
    "**Pasos:**\n",
    "1. Subir archivo exportado de ChromaDB a Google Drive\n",
    "2. Montar Google Drive en Colab\n",
    "3. Procesar con GPU T4/V100\n",
    "4. Descargar resultado para importar de vuelta\n",
    "\n",
    "**Ventajas:**\n",
    "- üöÄ **10-50x m√°s r√°pido** que procesamiento local\n",
    "- üÜì **Completamente gratis** con GPU T4\n",
    "- üíæ **Sin limitaciones de memoria** local\n",
    "- ‚ö° **Procesamiento en lotes optimizado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias necesarias\n",
    "!pip install sentence-transformers pandas pyarrow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Montar Google Drive y cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Configurar rutas\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/ChromaDB_Export\"\n",
    "INPUT_FILE = f\"{DRIVE_BASE}/docs_ada_export.parquet\"  # o .json\n",
    "OUTPUT_FILE = f\"{DRIVE_BASE}/docs_e5large_processed.parquet\"\n",
    "CHECKPOINT_FILE = f\"{DRIVE_BASE}/e5_colab_checkpoint.json\"\n",
    "\n",
    "print(f\"üìÅ Rutas configuradas:\")\n",
    "print(f\"   Input: {INPUT_FILE}\")\n",
    "print(f\"   Output: {OUTPUT_FILE}\")\n",
    "print(f\"   Checkpoint: {CHECKPOINT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos exportados\n",
    "try:\n",
    "    # Intentar cargar Parquet primero (m√°s eficiente)\n",
    "    if INPUT_FILE.endswith('.parquet'):\n",
    "        df = pd.read_parquet(INPUT_FILE)\n",
    "        print(f\"‚úÖ Cargado archivo Parquet: {len(df):,} documentos\")\n",
    "    else:\n",
    "        # Cargar JSON como fallback\n",
    "        with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Convertir a DataFrame\n",
    "        records = []\n",
    "        for i, (doc, meta) in enumerate(zip(data['documents'], data['metadatas'])):\n",
    "            record = {'document': doc, 'id': f\"doc_{i}\"}\n",
    "            if meta:\n",
    "                record.update(meta)\n",
    "            records.append(record)\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        print(f\"‚úÖ Cargado archivo JSON: {len(df):,} documentos\")\n",
    "    \n",
    "    # Mostrar informaci√≥n del dataset\n",
    "    print(f\"\\nüìä Informaci√≥n del dataset:\")\n",
    "    print(f\"   Filas: {len(df):,}\")\n",
    "    print(f\"   Columnas: {list(df.columns)}\")\n",
    "    print(f\"   Memoria: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
    "    \n",
    "    # Mostrar muestra\n",
    "    print(f\"\\nüìã Muestra de datos:\")\n",
    "    print(df.head(2).to_string())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando datos: {e}\")\n",
    "    print(\"\\nüí° Aseg√∫rate de que el archivo exportado est√© en Google Drive en la ruta correcta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cargar modelo E5-Large-v2 optimizado para GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo E5-Large-v2 con optimizaciones GPU\n",
    "print(\"üì• Cargando modelo E5-Large-v2...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model = SentenceTransformer('intfloat/e5-large-v2')\n",
    "\n",
    "# Optimizar para GPU si est√° disponible\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "    print(f\"‚úÖ Modelo cargado en GPU en {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "    # Configurar para m√°ximo rendimiento\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"‚ö° Optimizaciones GPU activadas\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Modelo cargado en CPU en {time.time() - start_time:.1f}s\")\n",
    "    print(\"üí° Para mejor rendimiento, activa GPU en Runtime > Change runtime type\")\n",
    "\n",
    "print(f\"üìè Dimensiones del modelo: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funciones de procesamiento optimizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_e5(text: str) -> str:\n",
    "    \"\"\"Preprocesar texto para E5-Large con optimizaciones\"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return \"passage: empty document\"\n",
    "    \n",
    "    # Limpiar texto\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Truncar inteligentemente para E5 (√≥ptimo ~512 tokens)\n",
    "    if len(text) > 2000:  # ~1500 tokens aprox\n",
    "        # Mantener inicio y final para preservar contexto\n",
    "        text = text[:1000] + \" ... \" + text[-1000:]\n",
    "    \n",
    "    # Prefijo requerido por E5\n",
    "    return f\"passage: {text}\"\n",
    "\n",
    "def save_checkpoint(processed_count: int, total_count: int, results: list):\n",
    "    \"\"\"Guardar checkpoint del progreso\"\"\"\n",
    "    checkpoint_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"processed_count\": processed_count,\n",
    "        \"total_count\": total_count,\n",
    "        \"progress_percent\": (processed_count / total_count * 100) if total_count > 0 else 0,\n",
    "        \"results_count\": len(results)\n",
    "    }\n",
    "    \n",
    "    with open(CHECKPOINT_FILE, 'w') as f:\n",
    "        json.dump(checkpoint_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Checkpoint guardado: {processed_count:,}/{total_count:,} ({checkpoint_data['progress_percent']:.1f}%)\")\n",
    "\n",
    "def load_checkpoint():\n",
    "    \"\"\"Cargar checkpoint si existe\"\"\"\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "        print(f\"üìÇ Checkpoint encontrado: {checkpoint['processed_count']:,}/{checkpoint['total_count']:,} procesados\")\n",
    "        return checkpoint['processed_count']\n",
    "    except FileNotFoundError:\n",
    "        print(\"üÜï Iniciando procesamiento desde cero\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error cargando checkpoint: {e}\")\n",
    "        return 0\n",
    "\n",
    "print(\"‚úÖ Funciones de procesamiento definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Procesamiento principal con GPU acelerado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de procesamiento\n",
    "BATCH_SIZE = 64 if torch.cuda.is_available() else 16  # M√°s grande para GPU\n",
    "CHECKPOINT_FREQUENCY = 500  # Guardar cada 500 documentos\n",
    "\n",
    "print(f\"‚öôÔ∏è  Configuraci√≥n:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Checkpoint cada: {CHECKPOINT_FREQUENCY} docs\")\n",
    "print(f\"   Total documentos: {len(df):,}\")\n",
    "\n",
    "# Cargar checkpoint si existe\n",
    "start_index = load_checkpoint()\n",
    "\n",
    "if start_index >= len(df):\n",
    "    print(\"‚úÖ ¬°Procesamiento ya completado!\")\n",
    "else:\n",
    "    print(f\"üöÄ Iniciando procesamiento desde √≠ndice {start_index:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento principal\n",
    "results = []\n",
    "total_docs = len(df)\n",
    "start_time = time.time()\n",
    "\n",
    "# Filtrar documentos v√°lidos desde el √≠ndice de inicio\n",
    "remaining_df = df.iloc[start_index:].copy()\n",
    "valid_docs = remaining_df[remaining_df['document'].notna() & (remaining_df['document'].str.len() > 0)]\n",
    "\n",
    "print(f\"üìä Documentos v√°lidos para procesar: {len(valid_docs):,}\")\n",
    "print(f\"üìä Documentos saltados (vac√≠os): {len(remaining_df) - len(valid_docs):,}\")\n",
    "\n",
    "if len(valid_docs) == 0:\n",
    "    print(\"‚ö†Ô∏è  No hay documentos v√°lidos para procesar\")\n",
    "else:\n",
    "    print(\"\\nüî• Iniciando procesamiento con GPU...\")\n",
    "    \n",
    "    try:\n",
    "        # Procesar en lotes\n",
    "        for i in tqdm(range(0, len(valid_docs), BATCH_SIZE), desc=\"Procesando lotes\"):\n",
    "            batch_df = valid_docs.iloc[i:i + BATCH_SIZE]\n",
    "            \n",
    "            # Preprocesar textos para E5\n",
    "            texts = [preprocess_for_e5(doc) for doc in batch_df['document']]\n",
    "            \n",
    "            # Generar embeddings con GPU\n",
    "            batch_start = time.time()\n",
    "            embeddings = model.encode(\n",
    "                texts,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                show_progress_bar=False,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=False  # E5 no requiere normalizaci√≥n\n",
    "            )\n",
    "            batch_time = time.time() - batch_start\n",
    "            \n",
    "            # Guardar resultados\n",
    "            for idx, (_, row) in enumerate(batch_df.iterrows()):\n",
    "                result = {\n",
    "                    'id': f\"e5_doc_{start_index + i + idx}\",\n",
    "                    'document': row['document'],\n",
    "                    'embedding': embeddings[idx].tolist(),\n",
    "                    'metadata': {k: v for k, v in row.items() if k != 'document'}\n",
    "                }\n",
    "                results.append(result)\n",
    "            \n",
    "            # Estad√≠sticas de rendimiento\n",
    "            processed_count = start_index + i + len(batch_df)\n",
    "            docs_per_sec = len(batch_df) / batch_time\n",
    "            \n",
    "            if (i + BATCH_SIZE) % (CHECKPOINT_FREQUENCY // BATCH_SIZE * BATCH_SIZE) == 0 or i + BATCH_SIZE >= len(valid_docs):\n",
    "                elapsed_time = time.time() - start_time\n",
    "                total_processed = len(results)\n",
    "                overall_speed = total_processed / elapsed_time\n",
    "                eta_seconds = (total_docs - processed_count) / overall_speed if overall_speed > 0 else 0\n",
    "                \n",
    "                print(f\"\\nüìä Progreso:\")\n",
    "                print(f\"   Procesados: {processed_count:,}/{total_docs:,} ({processed_count/total_docs*100:.1f}%)\")\n",
    "                print(f\"   Velocidad lote: {docs_per_sec:.1f} docs/seg\")\n",
    "                print(f\"   Velocidad promedio: {overall_speed:.1f} docs/seg\")\n",
    "                print(f\"   Tiempo transcurrido: {elapsed_time/60:.1f} min\")\n",
    "                print(f\"   ETA: {eta_seconds/60:.1f} min\")\n",
    "                \n",
    "                # Guardar checkpoint\n",
    "                save_checkpoint(processed_count, total_docs, results)\n",
    "                \n",
    "                # Limpiar memoria GPU\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error durante procesamiento: {e}\")\n",
    "        print(\"üíæ Guardando progreso parcial...\")\n",
    "        save_checkpoint(len(results), total_docs, results)\n",
    "        raise\n",
    "    \n",
    "    # Resumen final\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nüéâ ¬°Procesamiento completado!\")\n",
    "    print(f\"   Total procesado: {len(results):,} documentos\")\n",
    "    print(f\"   Tiempo total: {total_time/60:.1f} minutos\")\n",
    "    print(f\"   Velocidad promedio: {len(results)/total_time:.1f} docs/seg\")\n",
    "    print(f\"   Dimensiones embeddings: {len(results[0]['embedding'])} (debe ser 1024)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardar resultados finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir resultados a formato final\n",
    "if results:\n",
    "    print(\"üíæ Preparando datos finales...\")\n",
    "    \n",
    "    final_data = {\n",
    "        'export_info': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model': 'intfloat/e5-large-v2',\n",
    "            'dimensions': 1024,\n",
    "            'total_documents': len(results),\n",
    "            'processing_time_minutes': (time.time() - start_time) / 60,\n",
    "            'colab_gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n",
    "        },\n",
    "        'documents': [r['document'] for r in results],\n",
    "        'embeddings': [r['embedding'] for r in results],\n",
    "        'metadatas': [r['metadata'] for r in results],\n",
    "        'ids': [r['id'] for r in results]\n",
    "    }\n",
    "    \n",
    "    # Guardar como JSON (compatible con el script de importaci√≥n)\n",
    "    json_output = OUTPUT_FILE.replace('.parquet', '.json')\n",
    "    print(f\"üíæ Guardando resultados en: {json_output}\")\n",
    "    \n",
    "    with open(json_output, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Tambi√©n guardar como Parquet para eficiencia\n",
    "    try:\n",
    "        results_df = pd.DataFrame([\n",
    "            {\n",
    "                'id': r['id'],\n",
    "                'document': r['document'],\n",
    "                'embedding': r['embedding'],\n",
    "                **r['metadata']\n",
    "            } for r in results\n",
    "        ])\n",
    "        \n",
    "        results_df.to_parquet(OUTPUT_FILE, index=False)\n",
    "        print(f\"‚úÖ Guardado adicional en Parquet: {OUTPUT_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  No se pudo guardar en Parquet: {e}\")\n",
    "    \n",
    "    # Verificar archivos guardados\n",
    "    import os\n",
    "    json_size = os.path.getsize(json_output) / (1024 * 1024)\n",
    "    print(f\"\\nüìä Archivos generados:\")\n",
    "    print(f\"   JSON: {json_output} ({json_size:.1f} MB)\")\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        parquet_size = os.path.getsize(OUTPUT_FILE) / (1024 * 1024)\n",
    "        print(f\"   Parquet: {OUTPUT_FILE} ({parquet_size:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ¬°Procesamiento completado exitosamente!\")\n",
    "    print(f\"üìÅ Descarga los archivos desde Google Drive para importar de vuelta a ChromaDB\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No hay resultados para guardar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verificaci√≥n final y estad√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n final\n",
    "if results:\n",
    "    print(\"üîç Verificaci√≥n final:\")\n",
    "    print(f\"   Documentos procesados: {len(results):,}\")\n",
    "    print(f\"   Dimensiones embeddings: {len(results[0]['embedding'])}\")\n",
    "    \n",
    "    # Verificar que todas las dimensiones sean correctas\n",
    "    dims_check = all(len(r['embedding']) == 1024 for r in results[:100])  # Verificar muestra\n",
    "    print(f\"   Dimensiones correctas: {'‚úÖ' if dims_check else '‚ùå'}\")\n",
    "    \n",
    "    # Estad√≠sticas de embeddings\n",
    "    sample_embedding = np.array(results[0]['embedding'])\n",
    "    print(f\"   Rango embeddings: [{sample_embedding.min():.3f}, {sample_embedding.max():.3f}]\")\n",
    "    print(f\"   Media embedding: {sample_embedding.mean():.3f}\")\n",
    "    \n",
    "    # Memoria GPU final\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.memory_allocated() / 1e9\n",
    "        memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"   Memoria GPU: {memory_used:.1f}/{memory_total:.1f} GB\")\n",
    "    \n",
    "    print(\"\\nüéâ ¬°Todo listo! Los archivos est√°n listos para descargar e importar.\")\n",
    "    print(\"\\nüìã Pr√≥ximos pasos:\")\n",
    "    print(\"1. Descargar el archivo JSON/Parquet desde Google Drive\")\n",
    "    print(\"2. Ejecutar el script de importaci√≥n en tu m√°quina local\")\n",
    "    print(\"3. Verificar la importaci√≥n con verify_e5_migration.py\")\n",
    "    print(\"4. ¬°Disfrutar de E5-Large-v2 s√∫per r√°pido!\")\n",
    "else:\n",
    "    print(\"‚ùå No se generaron resultados v√°lidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Comparaci√≥n con embeddings Ada-002 (Opcional)\n\nSi tienes embeddings Ada-002 existentes, puedes ejecutar esta secci√≥n para generar m√©tricas de comparaci√≥n.",
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}