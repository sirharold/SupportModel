# ğŸ”¬ AnÃ¡lisis Interactivo de BÃºsqueda - GuÃ­a de Uso

## ğŸ“‹ DescripciÃ³n

Nueva pÃ¡gina en Streamlit que permite analizar interactivamente el proceso completo de bÃºsqueda vectorial y reranking, replicando la lÃ³gica del Colab pero de forma visual e interactiva.

## ğŸ¯ Funcionalidades

### 1. **SelecciÃ³n de Pregunta**
- Selecciona cualquiera de las **2,067 preguntas validadas** (questions_withlinks)
- Visualiza la pregunta y sus enlaces de ground truth
- Usa un input numÃ©rico para navegar rÃ¡pidamente

### 2. **BÃºsqueda Vectorial (Antes del Reranking)**
- Busca en ChromaDB usando similitud coseno
- Muestra los top-K documentos recuperados
- Indica cuÃ¡les son relevantes (âœ…) segÃºn ground truth
- Muestra scores de similitud coseno

### 3. **Reranking con CrossEncoder**
- Aplica el modelo `cross-encoder/ms-marco-MiniLM-L-6-v2`
- NormalizaciÃ³n Min-Max de scores (igual que en Colab)
- Muestra cÃ³mo cambian los rankings
- Indica si documentos suben ğŸ”¼, bajan ğŸ”½ o se mantienen â¡ï¸

### 4. **MÃ©tricas de RecuperaciÃ³n**
Se calculan **antes y despuÃ©s** del reranking:

- **Precision@k**: ProporciÃ³n de documentos relevantes en top-k
- **Recall@k**: ProporciÃ³n de documentos relevantes recuperados
- **F1@k**: Media armÃ³nica de Precision y Recall
- **MAP@k**: Mean Average Precision
- **NDCG@k**: Normalized Discounted Cumulative Gain
- **MRR**: Mean Reciprocal Rank

### 5. **ComparaciÃ³n Visual**
- Tabla comparativa de mÃ©tricas antes vs despuÃ©s
- Deltas visuales (â–²â–¼) para ver mejoras/degradaciones
- Colores verde (mejora) / rojo (degradaciÃ³n)

## ğŸš€ CÃ³mo Usar

### Paso 1: Iniciar la AplicaciÃ³n
```bash
cd /Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel
streamlit run src/apps/main_qa_app.py
```

### Paso 2: NavegaciÃ³n
1. En el menÃº lateral, selecciona **"ğŸ”¬ AnÃ¡lisis Interactivo de BÃºsqueda"**

### Paso 3: ConfiguraciÃ³n
En el sidebar:
- **Modelo de Embedding**: Elige entre Ada, MPNet, MiniLM, E5-Large
- **Top-K**: NÃºmero de documentos a recuperar (5-20)
- **Valores de k**: Selecciona para quÃ© valores calcular mÃ©tricas (1, 3, 5, 10, 15)

### Paso 4: SelecciÃ³n de Pregunta
- **Ãndice de pregunta**: Ingresa un nÃºmero entre 0 y 2,066
  - Ejemplo: `0` para la primera pregunta
  - Ejemplo: `25` para la pregunta #26
  - Ejemplo: `100` para la pregunta #101
- Visualiza los enlaces de ground truth asociados

### Paso 5: Ejecutar AnÃ¡lisis
1. Click en **"ğŸš€ Ejecutar BÃºsqueda y AnÃ¡lisis"**
2. El sistema:
   - Busca documentos por similitud coseno
   - Muestra resultados iniciales y mÃ©tricas
   - Aplica CrossEncoder para reranking
   - Muestra resultados rerankeados y mÃ©tricas
   - Calcula deltas automÃ¡ticamente

### Paso 6: Interpretar Resultados

#### Documentos Antes del Reranking
- âœ… = Documento relevante (estÃ¡ en ground truth)
- âŒ = Documento no relevante
- Score de similitud coseno

#### Documentos DespuÃ©s del Reranking
- âœ…/âŒ = Relevancia
- ğŸ”¼ = SubiÃ³ posiciones (mejorÃ³ ranking)
- ğŸ”½ = BajÃ³ posiciones (empeorÃ³ ranking)
- â¡ï¸ = Mantuvo posiciÃ³n
- CrossEncoder Score normalizado

#### MÃ©tricas
- Verde â–² = Mejora despuÃ©s del reranking
- Rojo â–¼ = DegradaciÃ³n despuÃ©s del reranking
- Valores absolutos y cambios relativos

## ğŸ“Š Casos de Uso

### Caso 1: Analizar Pregunta EspecÃ­fica
Quieres ver cÃ³mo se comporta el sistema con una pregunta particular:
```
1. Ingresa el Ã­ndice: 50
2. Ejecuta el anÃ¡lisis
3. Observa si el reranking ayuda o perjudica
```

### Caso 2: Comparar Modelos
Quieres ver cuÃ¡l modelo funciona mejor para una pregunta:
```
1. Selecciona pregunta: 100
2. Prueba con Ada â†’ ejecuta anÃ¡lisis â†’ anota mÃ©tricas
3. Prueba con MPNet â†’ ejecuta anÃ¡lisis â†’ anota mÃ©tricas
4. Compara resultados
```

### Caso 3: Evaluar Impacto del Reranking
Quieres ver si el reranking ayuda en general:
```
1. Prueba varias preguntas (ej: 0, 25, 50, 100, 200)
2. Observa las deltas (â–²â–¼)
3. Identifica patrones: Â¿CuÃ¡ndo ayuda? Â¿CuÃ¡ndo perjudica?
```

### Caso 4: Debugging de Resultados
El sistema no encuentra un documento esperado:
```
1. Ingresa la pregunta problemÃ¡tica
2. Revisa los documentos recuperados
3. Verifica si estÃ¡ en top-K o no fue recuperado
4. Analiza los scores para entender por quÃ©
```

## ğŸ”§ Arquitectura TÃ©cnica

### Flujo de Datos
```
1. Usuario selecciona pregunta â†’ questions_withlinks (ChromaDB)
2. Sistema obtiene embedding de la pregunta
3. BÃºsqueda vectorial â†’ docs_{model} (ChromaDB)
4. CÃ¡lculo de mÃ©tricas â†’ Metrics Before
5. Aplicar CrossEncoder â†’ Reranked docs
6. CÃ¡lculo de mÃ©tricas â†’ Metrics After
7. ComparaciÃ³n y visualizaciÃ³n
```

### Colecciones ChromaDB Usadas
- `questions_withlinks`: 2,067 preguntas validadas (embeddings ya generados)
- `docs_ada`: Documentos con embeddings de Ada
- `docs_mpnet`: Documentos con embeddings de MPNet
- `docs_minilm`: Documentos con embeddings de MiniLM
- `docs_e5large`: Documentos con embeddings de E5-Large

### Modelos Cargados
- **Embeddings**: Ya generados, se obtienen de ChromaDB
- **CrossEncoder**: `cross-encoder/ms-marco-MiniLM-L-6-v2` (cacheado)

## âš¡ Rendimiento

- **Primera ejecuciÃ³n**: ~5-10 segundos (carga CrossEncoder)
- **Ejecuciones posteriores**: ~2-3 segundos (modelo cacheado)
- **Memoria**: ~1GB adicional (CrossEncoder en RAM)

## ğŸ” Diferencias con Colab

| Aspecto | Colab | Streamlit Interactive |
|---------|-------|----------------------|
| **Interfaz** | CÃ³digo + outputs | Visual interactiva |
| **EjecuciÃ³n** | Todas las 2,067 preguntas | Una o varias seleccionadas |
| **Tiempo** | 10+ horas | 2-3 segundos por pregunta |
| **MÃ©tricas** | Promedios agregados | Valores por pregunta individual |
| **VisualizaciÃ³n** | Prints en consola | Tablas y deltas visuales |
| **PropÃ³sito** | EvaluaciÃ³n completa | AnÃ¡lisis y debugging |

## ğŸ“ Notas Importantes

1. **Ground Truth**: Solo preguntas con enlaces validados (2,067 de 13,436)
2. **NormalizaciÃ³n URL**: Se aplica igual que en Colab (sin query params ni fragments)
3. **Scores CrossEncoder**: NormalizaciÃ³n Min-Max igual que en Colab
4. **MÃ©tricas**: FÃ³rmulas idÃ©nticas a las del Colab

## ğŸ“ Para Tesis

Esta herramienta es Ãºtil para:
- Ilustrar el funcionamiento del sistema en la presentaciÃ³n
- Analizar casos especÃ­ficos para discusiÃ³n en CapÃ­tulo 7
- Debugging y validaciÃ³n de resultados del Colab
- Generar screenshots para el documento

## ğŸ› Troubleshooting

### Error: "No se puede conectar a ChromaDB"
```bash
# Verifica que ChromaDB estÃ© corriendo
# Verifica la ruta en get_chromadb_client()
```

### Error: "No se encontrÃ³ colecciÃ³n"
```bash
# Verifica que las colecciones existan:
# - questions_withlinks
# - docs_{model}
```

### La pÃ¡gina no aparece en el menÃº
```bash
# Verifica que agregaste el import:
# from src.apps.interactive_search_analysis import show_interactive_search_analysis_page

# Y que agregaste la opciÃ³n en el radio:
# "ğŸ”¬ AnÃ¡lisis Interactivo de BÃºsqueda"
```

## ğŸ“ Soporte

Para problemas o mejoras, revisar:
- `/Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/src/apps/interactive_search_analysis.py`
- Logs de Streamlit en consola

---

**Autor**: Sistema RAG - Proyecto de MagÃ­ster
**Fecha**: Noviembre 2025
**VersiÃ³n**: 1.0
