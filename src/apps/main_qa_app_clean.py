import multiprocessing
import os
import time
import pandas as pd

# Set multiprocessing start method to 'spawn' and disable tokenizers parallelism
# This must be done before any other imports that might initialize multiprocessing
if multiprocessing.get_start_method(allow_none=True) != 'spawn':
    multiprocessing.set_start_method('spawn', force=True)
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import streamlit as st
import plotly.express as px
import json
import numpy as np
from src.core.qa_pipeline import answer_question_documents_only, answer_question_with_rag
from src.services.auth.clients import initialize_clients
from src.services.local_models import preload_tinyllama_model
from src.apps.data_analysis_page import show_data_analysis_page
from src.apps.cumulative_metrics_create import show_cumulative_metrics_create_page
from src.apps.cumulative_metrics_results_matplotlib import show_cumulative_metrics_results_page as show_cumulative_metrics_results_matplotlib_page
from src.config.config import EMBEDDING_MODELS, DEFAULT_EMBEDDING_MODEL, CHROMADB_COLLECTION_CONFIG, GENERATIVE_MODELS, DEFAULT_GENERATIVE_MODEL, GENERATIVE_MODEL_DESCRIPTIONS

def _sanitize_json_string(json_string: str) -> str:
    """Sanitiza una cadena JSON eliminando caracteres de control inv√°lidos."""
    import re
    
    # M√©todo m√°s robusto: usar regex para remover todos los caracteres de control
    # ASCII control characters (0-31) except \t(9), \n(10), \r(13)
    sanitized = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', json_string)
    
    # Tambi√©n remover caracteres Unicode problem√°ticos
    sanitized = re.sub(r'[\u0080-\u009F]', '', sanitized)  # C1 control characters
    sanitized = re.sub(r'[\u2028\u2029]', '', sanitized)   # Line/Paragraph separators
    
    # Remove any remaining non-printable characters
    sanitized = re.sub(r'[^\x20-\x7E\t\n\r]', '', sanitized)
    
    return sanitized

# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="Azure Q&A Expert System", 
    layout="wide", 
    page_icon="‚òÅÔ∏è"
)

# Session state para la barra de progreso
if 'progress' not in st.session_state:
    st.session_state.progress = 0

# Initialize clients
openai_client, openai_embedding_client, _ = initialize_clients()

# Precargar modelos locales en la primera ejecuci√≥n
if 'models_loaded' not in st.session_state:
    with st.spinner("üéØ Cargando componentes del sistema..."):
        progress_placeholder = st.empty()
        progress_bar = progress_placeholder.progress(0)
        
        # Simulaci√≥n de carga de componentes con progreso m√°s detallado
        progress_bar.progress(25, text="üîß Inicializando ChromaDB...")
        time.sleep(0.5)
        
        progress_bar.progress(50, text="üß† Cargando modelos de embedding...")
        time.sleep(0.5)
        
        progress_bar.progress(75, text="üöÄ Preparando modelo generativo TinyLlama...")
        preload_tinyllama_model()  # Asegurar que TinyLlama est√© precargado
        
        progress_bar.progress(100, text="‚úÖ Sistema listo!")
        time.sleep(0.5)
        
        progress_placeholder.empty()
        st.session_state.models_loaded = True

# Header con estilo mejorado
st.markdown("""
<style>
.main-header {
    background: linear-gradient(135deg, #0078d4 0%, #40e0d0 100%);
    padding: 2rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
}
</style>
<div class="main-header">
    <h1>‚òÅÔ∏è Azure Q&A Expert System</h1>
    <p>Sistema de Recuperaci√≥n Aumentada con Generaci√≥n (RAG) para documentaci√≥n de Azure</p>
</div>
""", unsafe_allow_html=True)

# Sidebar para navegaci√≥n y configuraci√≥n
st.sidebar.title("üß≠ Navegaci√≥n")
page = st.sidebar.radio(
    "Selecciona una p√°gina:",
    [
        "üîç B√∫squeda Individual",
        "üìà An√°lisis de Datos",
        "‚öôÔ∏è Configuraci√≥n M√©tricas Acumulativas",
        "üìä Resultados M√©tricas Acumulativas",
    ],
    index=0
)
st.sidebar.markdown("---")

st.sidebar.title("‚öôÔ∏è Configuraci√≥n")

# Selecci√≥n de modelo de embedding
model_name = st.sidebar.selectbox(
    "Selecciona el modelo de embedding:",
    options=list(EMBEDDING_MODELS.keys()),
    index=list(EMBEDDING_MODELS.keys()).index(DEFAULT_EMBEDDING_MODEL)
)

# Selecci√≥n de modelo generativo
generative_model_name = st.sidebar.selectbox(
    "Selecciona el modelo generativo:",
    options=list(GENERATIVE_MODELS.keys()),
    index=list(GENERATIVE_MODELS.keys()).index(DEFAULT_GENERATIVE_MODEL),
    help="TinyLlama es gratuito y funciona sin configuraci√≥n. Mistral requiere autorizaci√≥n en Hugging Face."
)

# Mostrar informaci√≥n del modelo seleccionado
if generative_model_name in GENERATIVE_MODEL_DESCRIPTIONS:
    model_info = GENERATIVE_MODEL_DESCRIPTIONS[generative_model_name]
    st.sidebar.success(f"üéØ **{model_info['cost']}** - {model_info['description']}")
    st.sidebar.info(f"üìã **Requisitos**: {model_info['requirements']}")
    
    # Advertencia especial para Mistral
    if generative_model_name == "mistral-7b":
        st.sidebar.warning("‚ö†Ô∏è **Atenci√≥n**: Mistral (7B) es muy pesado para laptops. Recomendamos usar TinyLlama (1.1B).")
        st.sidebar.info("üìÅ Mistral requiere ~14GB de descarga y 6-8GB RAM.")
        
        # Verificar memoria disponible
        try:
            import psutil
            available_memory = psutil.virtual_memory().available / (1024**3)
            if available_memory < 6:
                st.sidebar.error(f"üö´ Memoria insuficiente: {available_memory:.1f}GB disponible, 6GB+ requerido")
            else:
                st.sidebar.info(f"‚úÖ Memoria disponible: {available_memory:.1f}GB")
        except:
            pass
elif generative_model_name == "llama-4-scout":
    st.sidebar.success("üåü **Modelo de API Gratuito** - Llama-4-Scout via OpenRouter")
    st.sidebar.info("‚ÑπÔ∏è Si el modelo no est√° disponible temporalmente, intenta con TinyLlama como alternativa local.")
elif generative_model_name == "gemini-1.5-flash":
    st.sidebar.warning("üí∞ **Modelo de API** - Incurre en costos por uso")
elif generative_model_name == "gpt-4":
    st.sidebar.warning("üí∞ **Modelo de API** - Incurre en costos altos por uso")

# P√°ginas principales
if page == "üîç B√∫squeda Individual":
    # El contenido de b√∫squeda individual va aqu√≠
    # (Copiar todo el contenido de la p√°gina de b√∫squeda individual del archivo original)
    pass  # Por ahora dejamos vac√≠o
    
elif page == "üìà An√°lisis de Datos":
    show_data_analysis_page()
    
elif page == "‚öôÔ∏è Configuraci√≥n M√©tricas Acumulativas":
    show_cumulative_metrics_create_page()
    
elif page == "üìä Resultados M√©tricas Acumulativas":
    show_cumulative_metrics_results_matplotlib_page()

# Footer com√∫n
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    <p>üí° <strong>Tip:</strong> Para mejores resultados, s√© espec√≠fico en tus preguntas e incluye el servicio de Azure de inter√©s.</p>
    <p>üîß Sistema desarrollado con ChromaDB + sentence-transformers</p>
</div>
""", unsafe_allow_html=True)