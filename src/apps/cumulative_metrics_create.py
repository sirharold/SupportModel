"""
P√°gina de Creaci√≥n de Configuraci√≥n para M√©tricas Acumulativas
Permite configurar evaluaciones y enviarlas a Google Colab
"""

import streamlit as st
import time
import json
import os
from typing import List, Dict, Any
from src.config.config import EMBEDDING_MODELS, GENERATIVE_MODELS, CHROMADB_COLLECTION_CONFIG

# Importar utilidades
from src.data.memory_utils import get_memory_usage, cleanup_memory
from src.services.storage.real_gdrive_integration import (
    show_gdrive_status, create_evaluation_config_in_drive,
    check_evaluation_status_in_drive, show_gdrive_authentication_instructions, 
    show_gdrive_debug_info
)
from src.apps.cumulative_metrics_page import display_current_colab_status


def show_cumulative_metrics_create_page():
    """P√°gina principal para crear configuraciones de m√©tricas acumulativas."""
    
    st.title("‚öôÔ∏è Configuraci√≥n M√©tricas Acumulativas - ACTUALIZADO")
    st.markdown("""
    Esta p√°gina permite configurar evaluaciones de m√∫ltiples preguntas y enviarlas a Google Colab para procesamiento con GPU.
    """)
    
    # Mostrar informaci√≥n del flujo
    st.info("""
    üìã **Flujo de trabajo:**
    1. **Configurar evaluaci√≥n** en esta p√°gina
    2. **Enviar a Google Drive** para Colab
    3. **Ejecutar en Google Colab** con GPU
    4. **Ver resultados** en la p√°gina de resultados
    """)
    
    # Configuraci√≥n inicial
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Configuraci√≥n de Datos")
        
        # Informaci√≥n sobre la fuente de datos
        st.info("üöÄ Las preguntas se extraen desde la colecci√≥n optimizada 'questions_withlinks' que contiene solo preguntas PRE-VALIDADAS con enlaces de Microsoft Learn que existen en la collection de documentos. Esto garantiza m√°xima velocidad y precisi√≥n.")
        
        # N√∫mero de preguntas
        num_questions = st.number_input(
            "üî¢ N√∫mero de preguntas a evaluar:",
            min_value=1,
            max_value=3100,
            value=600,
            step=1,
            help="N√∫mero total de preguntas para la evaluaci√≥n"
        )
        
        # Tama√±o de lote
        batch_size = st.number_input(
            "üì¶ Tama√±o de lote:",
            min_value=1,
            max_value=100,
            value=50,
            step=1,
            help="N√∫mero de preguntas a procesar por lote (afecta uso de memoria)"
        )
        
    with col2:
        st.subheader("ü§ñ Configuraci√≥n de Modelos")
        
        # Configuraci√≥n de modelo generativo
        generative_model_name = st.selectbox(
            "ü§ñ Modelo Generativo:",
            list(GENERATIVE_MODELS.keys()),
            index=list(GENERATIVE_MODELS.keys()).index("gpt-4") if "gpt-4" in GENERATIVE_MODELS else 0,
            help="Modelo usado para reranking LLM"
        )
        
        # Configuraci√≥n de recuperaci√≥n
        top_k = st.number_input(
            "üîù Top-K documentos:",
            min_value=1,
            max_value=50,
            value=10,
            step=1,
            help="N√∫mero m√°ximo de documentos a recuperar"
        )
        
        # M√©todo de reranking
        reranking_method = st.selectbox(
            "üîÑ M√©todo de Reranking:",
            options=["crossencoder", "standard", "none"],
            index=0,  # CrossEncoder por defecto
            format_func=lambda x: {
                "crossencoder": "üß† CrossEncoder (Recomendado)",
                "standard": "üìä Reranking Est√°ndar",
                "none": "‚ùå Sin Reranking"
            }[x],
            help="M√©todo de reranking: CrossEncoder usa ms-marco-MiniLM-L-6-v2 para mejor calidad"
        )
        
        # Mantener compatibilidad hacia atr√°s
        use_llm_reranker = reranking_method != "none"
        
        # NUEVO: Generar m√©tricas RAG
        generate_rag_metrics = st.checkbox(
            "üìù Generar M√©tricas RAG",
            value=True,
            help="Generar respuestas y calcular m√©tricas RAG (faithfulness, answer_relevance, etc.). Aumenta significativamente el tiempo de procesamiento."
        )
        
        if generate_rag_metrics:
            st.warning("‚ö†Ô∏è **Nota:** Activar m√©tricas RAG aumentar√° considerablemente el tiempo de evaluaci√≥n ya que se deben generar respuestas para cada pregunta.")
    
    # Selecci√≥n de modelos de embedding
    st.subheader("üìà Selecci√≥n de Modelos de Embedding")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üéØ Modelos Disponibles:**")
        
        # Opci√≥n para evaluar todos los modelos
        evaluate_all_models = st.checkbox(
            "üîÑ Evaluar todos los modelos",
            value=True,
            help="Eval√∫a autom√°ticamente todos los modelos disponibles"
        )
        
        if not evaluate_all_models:
            # Selecci√≥n manual de modelos
            selected_models = st.multiselect(
                "üìã Seleccionar modelos espec√≠ficos:",
                options=list(EMBEDDING_MODELS.keys()),
                default=[list(EMBEDDING_MODELS.keys())[0]],
                help="Selecciona uno o m√°s modelos para evaluar"
            )
        else:
            selected_models = list(EMBEDDING_MODELS.keys())
            st.write(f"‚úÖ Se evaluar√°n {len(selected_models)} modelos:")
            for model in selected_models:
                st.write(f"   ‚Ä¢ {model}")
    
    with col2:
        st.markdown("**üìä Informaci√≥n de la Evaluaci√≥n:**")
        
        if selected_models:
            total_evaluations = len(selected_models) * num_questions
            estimated_time_minutes = total_evaluations * 0.1 / 60  # Estimaci√≥n aproximada
            
            st.metric("üî¢ Modelos seleccionados", len(selected_models))
            st.metric("üî¢ Total evaluaciones", f"{total_evaluations:,}")
            st.metric("‚è±Ô∏è Tiempo estimado (GPU)", f"{estimated_time_minutes:.1f} min")
            
            # Mostrar detalles de configuraci√≥n
            st.markdown("**‚öôÔ∏è Configuraci√≥n:**")
            st.write(f"‚Ä¢ Preguntas: {num_questions:,}")
            st.write(f"‚Ä¢ Top-K: {top_k}")
            st.write(f"‚Ä¢ Reranking: {reranking_method}")
            st.write(f"‚Ä¢ M√©tricas RAG: {'‚úÖ' if generate_rag_metrics else '‚ùå'}")
            st.write(f"‚Ä¢ Lote: {batch_size}")
        else:
            st.warning("‚ö†Ô∏è Selecciona al menos un modelo para continuar")
    
    # Verificar Google Drive
    st.subheader("‚òÅÔ∏è Configuraci√≥n de Google Drive")
    
    gdrive_ok = show_gdrive_status()
    
    if not gdrive_ok:
        st.error("‚ùå Configuraci√≥n de Google Drive requerida")
        show_gdrive_authentication_instructions()
        
        col1, col2 = st.columns(2)
        with col1:
            # Verificar Estado button removed per user request
            st.empty()
        with col2:
            if st.button("üîç Debug Google Drive"):
                st.markdown("---")
                show_gdrive_debug_info()
        
        st.stop()
    
    # Crear configuraci√≥n
    if selected_models:
        
        # Preparar configuraci√≥n de evaluaci√≥n
        evaluation_config = {
            'num_questions': num_questions,
            'selected_models': selected_models,
            'generative_model_name': generative_model_name,
            'top_k': top_k,
            'use_llm_reranker': use_llm_reranker,  # Compatibilidad hacia atr√°s
            'reranking_method': reranking_method,  # Nuevo campo
            'generate_rag_metrics': generate_rag_metrics,
            'batch_size': batch_size,
            'evaluate_all_models': evaluate_all_models,
            'evaluation_type': 'cumulative_metrics_colab',
            'created_timestamp': time.time()
        }
        
        st.markdown("---")
        st.subheader("üöÄ Crear y Enviar Configuraci√≥n")
        
        # Mostrar resumen de configuraci√≥n
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä Resumen de Configuraci√≥n:**")
            st.json({
                'num_questions': num_questions,
                'selected_models': selected_models,
                'generative_model': generative_model_name,
                'top_k': top_k,
                'reranking_method': reranking_method,
                'llm_reranker': use_llm_reranker,
                'rag_metrics': generate_rag_metrics,
                'batch_size': batch_size
            })
        
        with col2:
            st.markdown("**üìÅ Google Drive:**")
            st.info("üìÇ Carpeta: `/TesisMagister/acumulative/`")
            st.info("üìÑ Se crear√°: `evaluation_config_TIMESTAMP.json`")
        
        # Botones de acci√≥n
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üöÄ Crear Configuraci√≥n y Enviar a Google Drive", type="primary"):
                create_config_and_send_to_drive(evaluation_config)
        
        with col2:
            # Verificar Estado button removed per user request
            st.empty()
        
        with col3:
            # Ver Resultados button removed per user request
            st.empty()
        
        # Mostrar estado actual
        st.markdown("---")
        display_current_colab_status()
    
    else:
        st.warning("‚ö†Ô∏è Por favor selecciona al menos un modelo para continuar")


def create_config_and_send_to_drive(evaluation_config: Dict):
    """Crea y env√≠a configuraci√≥n a Google Drive real - Compatible con cumulative metrics y N questions"""
    
    st.info("üì§ Creando configuraci√≥n y enviando a Google Drive...")
    
    try:
        # Detectar tipo de evaluaci√≥n
        evaluation_type = evaluation_config.get('evaluation_type', 'cumulative_metrics')
        
        # Obtener preguntas reales de la base de datos solo si no est√°n ya incluidas
        if 'questions_data' not in evaluation_config or evaluation_config['questions_data'] is None:
            with st.spinner("üì• Obteniendo preguntas de ChromaDB..."):
                from src.data.processing import fetch_random_questions_from_chromadb
                from src.services.auth.clients import initialize_clients
                
                try:
                    # Determinar modelo y configuraci√≥n seg√∫n el tipo
                    if evaluation_type == 'n_questions_cumulative_analysis':
                        # Para N questions, usar la configuraci√≥n anidada
                        first_model = list(evaluation_config['model_config']['embedding_models'].keys())[0]
                        num_questions = evaluation_config['data_config']['num_questions']
                        generative_model = evaluation_config['model_config']['generative_model']
                    else:
                        # Para cumulative metrics, usar la configuraci√≥n plana
                        first_model = evaluation_config['selected_models'][0]
                        num_questions = evaluation_config['num_questions']
                        generative_model = evaluation_config['generative_model_name']
                    
                    # Inicializar clientes
                    chromadb_wrapper, embedding_client, openai_client, gemini_client, local_tinyllama_client, local_mistral_client, openrouter_client, client = initialize_clients(
                        model_name=first_model,
                        generative_model_name=generative_model
                    )
                    
                    # Obtener preguntas optimizadas de la colecci√≥n pre-validada
                    with st.spinner(f"üöÄ Obteniendo {num_questions} preguntas optimizadas..."):
                        from src.data.optimized_questions import get_optimized_questions_batch
                        
                        questions = get_optimized_questions_batch(
                            chromadb_wrapper=chromadb_wrapper,
                            num_questions=num_questions,
                            embedding_model_name=first_model
                        )
                        
                        if questions:
                            # Mostrar estad√≠sticas de las preguntas obtenidas
                            total_links = sum(q.get('total_links', 0) for q in questions)
                            total_valid_links = sum(q.get('valid_links', 0) for q in questions)
                            avg_success_rate = sum(q.get('validation_success_rate', 0) for q in questions) / len(questions) * 100
                            
                            st.write(f"‚úÖ Obtenidas {len(questions)} preguntas optimizadas")
                            st.write(f"üìä Total de links: {total_links}, Links v√°lidos: {total_valid_links}")
                            st.write(f"üéØ Tasa promedio de validaci√≥n: {avg_success_rate:.1f}%")
                        else:
                            st.warning("‚ö†Ô∏è No se pudieron obtener preguntas de la colecci√≥n optimizada")
                    
                    if questions:
                        evaluation_config['questions_data'] = questions
                        st.success(f"‚úÖ Obtenidas {len(questions)} preguntas con enlaces MS Learn")
                    else:
                        st.warning("‚ö†Ô∏è No se encontraron preguntas, usando configuraci√≥n sin datos")
                        evaluation_config['questions_data'] = None
                        
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error obteniendo preguntas: {e}")
                    evaluation_config['questions_data'] = None
        else:
            st.info("üìù Usando preguntas ya incluidas en la configuraci√≥n")
        
        # Enviar a Google Drive real
        with st.spinner("‚òÅÔ∏è Enviando configuraci√≥n a Google Drive..."):
            # Generar nombre de archivo basado en el tipo de evaluaci√≥n
            import time
            timestamp = int(time.time())
            
            if evaluation_type == 'n_questions_cumulative_analysis':
                filename = f"n_questions_config_{timestamp}.json"
            else:
                filename = f"evaluation_config_{timestamp}.json"
            
            result = create_evaluation_config_in_drive(evaluation_config, filename)
            
            if result['success']:
                st.success("‚úÖ ¬°Configuraci√≥n enviada exitosamente a Google Drive!")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìÑ Archivo creado:**")
                    st.code(result['config_filename'])
                    if 'web_link' in result:
                        st.markdown(f"[üîó Ver en Drive]({result['web_link']})")
                
                with col2:
                    st.markdown("**üìã Pr√≥ximos pasos:**")
                    st.markdown("""
                    1. Abrir Google Colab
                    2. Subir `Universal_Colab_Evaluator.ipynb` 
                    3. Activar GPU (T4)
                    4. Ejecutar todas las celdas
                    5. Volver a la p√°gina de resultados
                    """)
                
                # Results navigation button removed per user request
                st.info("Results button removed per user request")
                
                # Bot√≥n para descargar notebook si est√° disponible
                try:
                    notebook_path = "/Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/Universal_Colab_Evaluator.ipynb"
                    if os.path.exists(notebook_path):
                        with open(notebook_path, 'rb') as f:
                            notebook_content = f.read()
                        
                        st.download_button(
                            label="üì• Descargar Universal_Colab_Evaluator.ipynb",
                            data=notebook_content,
                            file_name="Universal_Colab_Evaluator.ipynb",
                            mime="application/json",
                            help="Descarga el notebook para ejecutar en Google Colab"
                        )
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error preparando descarga de notebook: {e}")
                
            else:
                st.error(f"‚ùå Error enviando configuraci√≥n: {result.get('error', 'Error desconocido')}")
                
    except Exception as e:
        st.error(f"‚ùå Error cr√≠tico: {e}")
        st.exception(e)


def check_colab_evaluation_status():
    """Verifica el estado de la evaluaci√≥n en Google Drive"""
    
    with st.spinner("üîç Verificando estado de evaluaci√≥n..."):
        status_result = check_evaluation_status_in_drive()
        
        if status_result['success']:
            status_data = status_result['status_data']
            
            st.markdown("### üìä Estado de Evaluaci√≥n")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üîÑ Estado", status_data.get('status', 'Desconocido'))
                st.metric("üìÖ √öltima actualizaci√≥n", status_data.get('timestamp', 'N/A')[:19] if status_data.get('timestamp') else 'N/A')
            
            with col2:
                st.metric("ü§ñ Modelos", status_data.get('models_to_evaluate', 'N/A'))
                st.metric("‚ùì Preguntas", status_data.get('questions_total', 'N/A'))
            
            with col3:
                st.metric("üöÄ GPU", "‚úÖ" if status_data.get('gpu_used') else "‚ùå")
                st.metric("‚è±Ô∏è Tiempo", f"{status_data.get('total_time_seconds', 0):.1f}s" if status_data.get('total_time_seconds') else 'N/A')
            
            # Mostrar detalles adicionales
            if status_data.get('status') == 'completed':
                st.success("üéâ ¬°Evaluaci√≥n completada! Puedes ver los resultados en la p√°gina de resultados.")
                
                # Results button removed per user request
                st.info("Results button removed per user request")
                    
            elif status_data.get('status') == 'running':
                st.info("‚è≥ Evaluaci√≥n en progreso... Verifica nuevamente en unos minutos.")
                
            elif status_data.get('status') == 'error':
                st.error("‚ùå Error en la evaluaci√≥n. Revisa los logs de Colab.")
                
        else:
            st.warning("‚ö†Ô∏è No se pudo verificar el estado. Aseg√∫rate de que Google Drive est√© configurado correctamente.")


if __name__ == "__main__":
    show_cumulative_metrics_create_page()