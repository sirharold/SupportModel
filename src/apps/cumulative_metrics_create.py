"""
P√°gina de Creaci√≥n de Configuraci√≥n para M√©tricas Acumulativas
Permite configurar evaluaciones y enviarlas a Google Colab
"""

import streamlit as st
import time
import json
import os
from typing import List, Dict, Any
from src.config.config import EMBEDDING_MODELS, GENERATIVE_MODELS, CHROMADB_COLLECTION_CONFIG

# Importar utilidades
from src.data.memory_utils import get_memory_usage, cleanup_memory
from src.services.storage.real_gdrive_integration import (
    show_gdrive_status, create_evaluation_config_in_drive,
    check_evaluation_status_in_drive, show_gdrive_authentication_instructions, 
    show_gdrive_debug_info
)
from src.apps.cumulative_metrics_page import display_current_colab_status


def show_cumulative_metrics_create_page():
    """P√°gina principal para crear configuraciones de m√©tricas acumulativas."""
    
    st.title("‚öôÔ∏è Configuraci√≥n M√©tricas Acumulativas - ACTUALIZADO")
    st.markdown("""
    Esta p√°gina permite configurar evaluaciones de m√∫ltiples preguntas y enviarlas a Google Colab para procesamiento con GPU.
    """)
    
    # Mostrar informaci√≥n del flujo
    st.info("""
    üìã **Flujo de trabajo:**
    1. **Configurar evaluaci√≥n** en esta p√°gina
    2. **Enviar a Google Drive** para Colab
    3. **Ejecutar en Google Colab** con GPU
    4. **Ver resultados** en la p√°gina de resultados
    """)
    
    # Configuraci√≥n inicial
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Configuraci√≥n de Datos")
        
        # Informaci√≥n sobre la fuente de datos
        st.info("üìö Las preguntas se cargan desde la colecci√≥n 'questions_withlinks' que contiene **2,067 preguntas validadas** con enlaces de Microsoft Learn que existen en la colecci√≥n de documentos.")
        
        # N√∫mero de preguntas
        num_questions = st.number_input(
            "üî¢ N√∫mero de preguntas a evaluar:",
            min_value=1,
            max_value=3100,
            value=600,
            step=1,
            help="N√∫mero total de preguntas para la evaluaci√≥n"
        )
        
        # Tama√±o de lote
        batch_size = st.number_input(
            "üì¶ Tama√±o de lote:",
            min_value=1,
            max_value=100,
            value=50,
            step=1,
            help="N√∫mero de preguntas a procesar por lote (afecta uso de memoria)"
        )

        # Filtro de a√±o/semestre
        year_filter = st.selectbox(
            "üìÖ Filtro Temporal:",
            options=["all", "2024", "2023.1", "2023.2", "2022", "2020"],
            index=0,  # "all" por defecto
            format_func=lambda x: {
                "all": "üåê Todas las preguntas (sin filtro)",
                "2024": "üìÖ 2024 completo",
                "2023.1": "üìÖ 2023 - Primer semestre (Ene-Jun)",
                "2023.2": "üìÖ 2023 - Segundo semestre (Jul-Dic)",
                "2022": "üìÖ 2022 completo",
                "2020": "üìÖ 2020 completo"
            }[x],
            help="Filtra preguntas por a√±o o semestre de creaci√≥n seg√∫n an√°lisis temporal"
        )

        # Mostrar informaci√≥n sobre el filtro seleccionado
        if year_filter != "all":
            expected_questions = {
                "2024": 666,      # 32.2% del ground truth
                "2023.1": 553,    # 26.8% del ground truth (Enero-Junio 2023)
                "2023.2": 720,    # 34.8% del ground truth (Julio-Diciembre 2023)
                "2022": 119,      # 5.8% del ground truth
                "2020": 9         # 0.4% del ground truth
            }
            available = expected_questions.get(year_filter, 0)
            st.info(f"üìä Preguntas disponibles para {year_filter}: **{available}** preguntas")
            st.success(f"‚úÖ El sistema cargar√° las 2,067 preguntas, las filtrar√° por per√≠odo, y luego limitar√° al n√∫mero solicitado")
        
    with col2:
        st.subheader("ü§ñ Configuraci√≥n de Modelos")
        
        # Configuraci√≥n de modelo generativo
        generative_model_name = st.selectbox(
            "ü§ñ Modelo Generativo:",
            list(GENERATIVE_MODELS.keys()),
            index=list(GENERATIVE_MODELS.keys()).index("gpt-4") if "gpt-4" in GENERATIVE_MODELS else 0,
            help="Modelo usado para reranking LLM"
        )
        
        # Configuraci√≥n de recuperaci√≥n
        top_k = st.number_input(
            "üîù Top-K documentos:",
            min_value=1,
            max_value=50,
            value=10,
            step=1,
            help="N√∫mero m√°ximo de documentos a recuperar"
        )
        
        # M√©todo de reranking
        reranking_method = st.selectbox(
            "üîÑ M√©todo de Reranking:",
            options=["crossencoder", "standard", "none"],
            index=0,  # CrossEncoder por defecto
            format_func=lambda x: {
                "crossencoder": "üß† CrossEncoder (Recomendado)",
                "standard": "üìä Reranking Est√°ndar",
                "none": "‚ùå Sin Reranking"
            }[x],
            help="M√©todo de reranking: CrossEncoder usa ms-marco-MiniLM-L-6-v2 para mejor calidad"
        )
        
        # Mantener compatibilidad hacia atr√°s
        use_llm_reranker = reranking_method != "none"
        
        # NUEVO: Generar m√©tricas RAG
        generate_rag_metrics = st.checkbox(
            "üìù Generar M√©tricas RAG",
            value=True,
            help="Generar respuestas y calcular m√©tricas RAG (faithfulness, answer_relevance, etc.). Aumenta significativamente el tiempo de procesamiento."
        )
        
        if generate_rag_metrics:
            st.warning("‚ö†Ô∏è **Nota:** Activar m√©tricas RAG aumentar√° considerablemente el tiempo de evaluaci√≥n ya que se deben generar respuestas para cada pregunta.")
    
    # Selecci√≥n de modelos de embedding
    st.subheader("üìà Selecci√≥n de Modelos de Embedding")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üéØ Modelos Disponibles:**")
        
        # Opci√≥n para evaluar todos los modelos
        evaluate_all_models = st.checkbox(
            "üîÑ Evaluar todos los modelos",
            value=True,
            help="Eval√∫a autom√°ticamente todos los modelos disponibles"
        )
        
        if not evaluate_all_models:
            # Selecci√≥n manual de modelos
            selected_models = st.multiselect(
                "üìã Seleccionar modelos espec√≠ficos:",
                options=list(EMBEDDING_MODELS.keys()),
                default=[list(EMBEDDING_MODELS.keys())[0]],
                help="Selecciona uno o m√°s modelos para evaluar"
            )
        else:
            selected_models = list(EMBEDDING_MODELS.keys())
            st.write(f"‚úÖ Se evaluar√°n {len(selected_models)} modelos:")
            for model in selected_models:
                st.write(f"   ‚Ä¢ {model}")
    
    with col2:
        st.markdown("**üìä Informaci√≥n de la Evaluaci√≥n:**")
        
        if selected_models:
            total_evaluations = len(selected_models) * num_questions
            estimated_time_minutes = total_evaluations * 0.1 / 60  # Estimaci√≥n aproximada
            
            st.metric("üî¢ Modelos seleccionados", len(selected_models))
            st.metric("üî¢ Total evaluaciones", f"{total_evaluations:,}")
            st.metric("‚è±Ô∏è Tiempo estimado (GPU)", f"{estimated_time_minutes:.1f} min")
            
            # Mostrar detalles de configuraci√≥n
            st.markdown("**‚öôÔ∏è Configuraci√≥n:**")
            st.write(f"‚Ä¢ Preguntas: {num_questions:,}")
            st.write(f"‚Ä¢ Filtro temporal: {year_filter}")
            st.write(f"‚Ä¢ Top-K: {top_k}")
            st.write(f"‚Ä¢ Reranking: {reranking_method}")
            st.write(f"‚Ä¢ M√©tricas RAG: {'‚úÖ' if generate_rag_metrics else '‚ùå'}")
            st.write(f"‚Ä¢ Lote: {batch_size}")
        else:
            st.warning("‚ö†Ô∏è Selecciona al menos un modelo para continuar")
    
    # Verificar Google Drive
    st.subheader("‚òÅÔ∏è Configuraci√≥n de Google Drive")
    
    gdrive_ok = show_gdrive_status()
    
    if not gdrive_ok:
        st.error("‚ùå Configuraci√≥n de Google Drive requerida")
        show_gdrive_authentication_instructions()
        
        col1, col2 = st.columns(2)
        with col1:
            # Verificar Estado button removed per user request
            st.empty()
        with col2:
            if st.button("üîç Debug Google Drive"):
                st.markdown("---")
                show_gdrive_debug_info()
        
        st.stop()
    
    # Crear configuraci√≥n
    if selected_models:
        
        # Preparar configuraci√≥n de evaluaci√≥n
        evaluation_config = {
            'num_questions': num_questions,
            'year_filter': year_filter,  # Filtro temporal
            'selected_models': selected_models,
            'generative_model_name': generative_model_name,
            'top_k': top_k,
            'use_llm_reranker': use_llm_reranker,  # Compatibilidad hacia atr√°s
            'reranking_method': reranking_method,  # Nuevo campo
            'generate_rag_metrics': generate_rag_metrics,
            'batch_size': batch_size,
            'evaluate_all_models': evaluate_all_models,
            'evaluation_type': 'cumulative_metrics_colab',
            'created_timestamp': time.time()
        }
        
        st.markdown("---")
        st.subheader("üöÄ Crear y Enviar Configuraci√≥n")
        
        # Mostrar resumen de configuraci√≥n
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä Resumen de Configuraci√≥n:**")
            st.json({
                'num_questions': num_questions,
                'year_filter': year_filter,
                'selected_models': selected_models,
                'generative_model': generative_model_name,
                'top_k': top_k,
                'reranking_method': reranking_method,
                'llm_reranker': use_llm_reranker,
                'rag_metrics': generate_rag_metrics,
                'batch_size': batch_size
            })
        
        with col2:
            st.markdown("**üìÅ Google Drive:**")
            st.info("üìÇ Carpeta: `/TesisMagister/acumulative/`")
            st.info("üìÑ Se crear√°: `evaluation_config_TIMESTAMP.json`")
        
        # Botones de acci√≥n
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üöÄ Crear Configuraci√≥n y Enviar a Google Drive", type="primary"):
                create_config_and_send_to_drive(evaluation_config)
        
        with col2:
            # Verificar Estado button removed per user request
            st.empty()
        
        with col3:
            # Ver Resultados button removed per user request
            st.empty()
        
        # Mostrar estado actual
        st.markdown("---")
        display_current_colab_status()
    
    else:
        st.warning("‚ö†Ô∏è Por favor selecciona al menos un modelo para continuar")


def filter_questions_by_year(questions: List[Dict], year_filter: str) -> List[Dict]:
    """
    Filtra preguntas por a√±o o semestre seg√∫n la fecha de creaci√≥n.

    Args:
        questions: Lista de preguntas de ChromaDB
        year_filter: Filtro temporal ('all', '2024', '2023.1', '2023.2', '2022', '2020')

    Returns:
        Lista de preguntas filtradas
    """
    if year_filter == "all" or not questions:
        return questions

    import json
    from datetime import datetime

    st.info(f"üîç Aplicando filtro temporal: {year_filter}")

    # Cargar archivo original con fechas (usando el an√°lisis temporal que ya hicimos)
    original_questions_path = "/Users/haroldgomez/Documents/ProyectoTituloMAgister/ScrappingMozilla/Logs al 20250602/questions_data.json"

    if not os.path.exists(original_questions_path):
        st.warning(f"‚ö†Ô∏è No se encontr√≥ archivo de fechas: {original_questions_path}")
        st.warning("‚ö†Ô∏è Devolviendo preguntas sin filtrar")
        return questions

    # Crear mapping URL -> fecha
    url_to_date = {}
    try:
        with open(original_questions_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        q = json.loads(line)
                        url = q.get('url', '')
                        date_str = q.get('date', '')
                        if url and date_str:
                            url_to_date[url] = date_str
                    except json.JSONDecodeError:
                        continue

        st.write(f"‚úÖ Cargadas {len(url_to_date):,} fechas del archivo original")
    except Exception as e:
        st.error(f"‚ùå Error cargando fechas: {e}")
        return questions

    # Filtrar preguntas
    filtered_questions = []
    skipped_no_date = 0
    skipped_parse_error = 0

    for q in questions:
        url = q.get('url', '')
        date_str = url_to_date.get(url)

        if not date_str:
            skipped_no_date += 1
            continue

        # Parse fecha
        try:
            # Manejar diferentes formatos de fecha ISO
            date_str_clean = date_str.replace('Z', '+00:00')
            if '+' in date_str_clean:
                date_str_clean = date_str_clean.split('+')[0]

            date_obj = datetime.fromisoformat(date_str_clean)
            year = date_obj.year
            month = date_obj.month

            # Aplicar filtro
            should_include = False

            if year_filter == "2024" and year == 2024:
                should_include = True
            elif year_filter == "2023.1" and year == 2023 and month <= 6:
                should_include = True
            elif year_filter == "2023.2" and year == 2023 and month > 6:
                should_include = True
            elif year_filter == "2022" and year == 2022:
                should_include = True
            elif year_filter == "2020" and year == 2020:
                should_include = True

            if should_include:
                filtered_questions.append(q)

        except Exception as e:
            skipped_parse_error += 1
            continue

    # Estad√≠sticas de filtrado
    st.success(f"‚úÖ Filtradas {len(filtered_questions)} preguntas para periodo: {year_filter}")

    if skipped_no_date > 0 or skipped_parse_error > 0:
        st.info(f"üìä Omitidas: {skipped_no_date} sin fecha, {skipped_parse_error} error parsing")

    # Validar que tenemos suficientes preguntas
    if len(filtered_questions) == 0:
        st.error(f"‚ùå No se encontraron preguntas para el periodo {year_filter}")
        st.warning("‚ö†Ô∏è Devolviendo preguntas sin filtrar")
        return questions

    return filtered_questions


def create_config_and_send_to_drive(evaluation_config: Dict):
    """Crea y env√≠a configuraci√≥n a Google Drive real - Compatible con cumulative metrics y N questions"""

    st.info("üì§ Creando configuraci√≥n y enviando a Google Drive...")
    
    try:
        # Detectar tipo de evaluaci√≥n
        evaluation_type = evaluation_config.get('evaluation_type', 'cumulative_metrics')
        
        # Obtener preguntas reales de la base de datos solo si no est√°n ya incluidas
        if 'questions_data' not in evaluation_config or evaluation_config['questions_data'] is None:
            with st.spinner("üì• Obteniendo preguntas de ChromaDB..."):
                from src.data.processing import fetch_random_questions_from_chromadb
                from src.services.auth.clients import initialize_clients
                
                try:
                    # Determinar modelo y configuraci√≥n seg√∫n el tipo
                    if evaluation_type == 'n_questions_cumulative_analysis':
                        # Para N questions, usar la configuraci√≥n anidada
                        first_model = list(evaluation_config['model_config']['embedding_models'].keys())[0]
                        num_questions = evaluation_config['data_config']['num_questions']
                        generative_model = evaluation_config['model_config']['generative_model']
                    else:
                        # Para cumulative metrics, usar la configuraci√≥n plana
                        first_model = evaluation_config['selected_models'][0]
                        num_questions = evaluation_config['num_questions']
                        generative_model = evaluation_config['generative_model_name']
                    
                    # Inicializar clientes
                    chromadb_wrapper, embedding_client, openai_client, gemini_client, local_tinyllama_client, local_mistral_client, openrouter_client, client = initialize_clients(
                        model_name=first_model,
                        generative_model_name=generative_model
                    )
                    
                    # Obtener preguntas de la colecci√≥n questions_withlinks
                    # Estas 2,067 preguntas YA est√°n validadas (tienen links que existen en los documentos)
                    year_filter = evaluation_config.get('year_filter', 'all')

                    if year_filter != 'all':
                        # Obtener TODAS las 2,067 preguntas para luego filtrar por per√≠odo
                        fetch_count = 2067  # Total disponible en questions_withlinks
                        st.info(f"üîç Filtro temporal activo: cargando las 2,067 preguntas validadas para filtrar por per√≠odo {year_filter}...")
                    else:
                        # Sin filtro, obtener solo las necesarias
                        fetch_count = min(num_questions, 2067)

                    with st.spinner(f"üì• Cargando {fetch_count} preguntas validadas desde questions_withlinks..."):
                        from src.data.optimized_questions import get_optimized_questions_batch

                        questions = get_optimized_questions_batch(
                            chromadb_wrapper=chromadb_wrapper,
                            num_questions=fetch_count,
                            embedding_model_name=first_model
                        )

                        if questions:
                            st.write(f"‚úÖ Cargadas {len(questions)} preguntas (con links ya validados)")

                            # Aplicar filtro temporal si est√° configurado
                            if year_filter != 'all':
                                st.markdown("---")
                                st.subheader("üìÖ Filtrando por Per√≠odo")
                                questions = filter_questions_by_year(questions, year_filter)

                                # Mostrar resultado del filtrado
                                if questions:
                                    st.success(f"‚úÖ Encontradas {len(questions)} preguntas para el per√≠odo {year_filter}")

                                    # Limitar al n√∫mero solicitado si hay m√°s disponibles
                                    if len(questions) > num_questions:
                                        st.info(f"‚úÇÔ∏è Limitando a {num_questions} preguntas (de las {len(questions)} disponibles)")
                                        questions = questions[:num_questions]
                                        st.write(f"üìä Conjunto final: {len(questions)} preguntas")
                        else:
                            st.warning("‚ö†Ô∏è No se pudieron cargar preguntas de la colecci√≥n questions_withlinks")
                    
                    if questions:
                        evaluation_config['questions_data'] = questions
                        st.success(f"‚úÖ Listas {len(questions)} preguntas validadas para evaluaci√≥n")
                    else:
                        st.warning("‚ö†Ô∏è No se encontraron preguntas, usando configuraci√≥n sin datos")
                        evaluation_config['questions_data'] = None
                        
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error obteniendo preguntas: {e}")
                    evaluation_config['questions_data'] = None
        else:
            st.info("üìù Usando preguntas ya incluidas en la configuraci√≥n")

            # Aplicar filtro temporal tambi√©n a preguntas pre-cargadas
            year_filter = evaluation_config.get('year_filter', 'all')
            if year_filter != 'all' and evaluation_config.get('questions_data'):
                st.markdown("---")
                st.subheader("üìÖ Aplicando Filtro Temporal a Preguntas Pre-cargadas")
                evaluation_config['questions_data'] = filter_questions_by_year(
                    evaluation_config['questions_data'],
                    year_filter
                )
        
        # Enviar a Google Drive real
        with st.spinner("‚òÅÔ∏è Enviando configuraci√≥n a Google Drive..."):
            # Generar nombre de archivo basado en el tipo de evaluaci√≥n
            import time
            timestamp = int(time.time())
            
            if evaluation_type == 'n_questions_cumulative_analysis':
                filename = f"n_questions_config_{timestamp}.json"
            else:
                filename = f"evaluation_config_{timestamp}.json"
            
            result = create_evaluation_config_in_drive(evaluation_config, filename)
            
            if result['success']:
                st.success("‚úÖ ¬°Configuraci√≥n enviada exitosamente a Google Drive!")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìÑ Archivo creado:**")
                    st.code(result['config_filename'])
                    if 'web_link' in result:
                        st.markdown(f"[üîó Ver en Drive]({result['web_link']})")
                
                with col2:
                    st.markdown("**üìã Pr√≥ximos pasos:**")
                    st.markdown("""
                    1. Abrir Google Colab
                    2. Subir `Universal_Colab_Evaluator.ipynb` 
                    3. Activar GPU (T4)
                    4. Ejecutar todas las celdas
                    5. Volver a la p√°gina de resultados
                    """)
                
                # Results navigation button removed per user request
                st.info("Results button removed per user request")
                
                # Bot√≥n para descargar notebook si est√° disponible
                try:
                    notebook_path = "/Users/haroldgomez/Documents/ProyectoTituloMAgister/SupportModel/Universal_Colab_Evaluator.ipynb"
                    if os.path.exists(notebook_path):
                        with open(notebook_path, 'rb') as f:
                            notebook_content = f.read()
                        
                        st.download_button(
                            label="üì• Descargar Universal_Colab_Evaluator.ipynb",
                            data=notebook_content,
                            file_name="Universal_Colab_Evaluator.ipynb",
                            mime="application/json",
                            help="Descarga el notebook para ejecutar en Google Colab"
                        )
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error preparando descarga de notebook: {e}")
                
            else:
                st.error(f"‚ùå Error enviando configuraci√≥n: {result.get('error', 'Error desconocido')}")
                
    except Exception as e:
        st.error(f"‚ùå Error cr√≠tico: {e}")
        st.exception(e)


def check_colab_evaluation_status():
    """Verifica el estado de la evaluaci√≥n en Google Drive"""
    
    with st.spinner("üîç Verificando estado de evaluaci√≥n..."):
        status_result = check_evaluation_status_in_drive()
        
        if status_result['success']:
            status_data = status_result['status_data']
            
            st.markdown("### üìä Estado de Evaluaci√≥n")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üîÑ Estado", status_data.get('status', 'Desconocido'))
                st.metric("üìÖ √öltima actualizaci√≥n", status_data.get('timestamp', 'N/A')[:19] if status_data.get('timestamp') else 'N/A')
            
            with col2:
                st.metric("ü§ñ Modelos", status_data.get('models_to_evaluate', 'N/A'))
                st.metric("‚ùì Preguntas", status_data.get('questions_total', 'N/A'))
            
            with col3:
                st.metric("üöÄ GPU", "‚úÖ" if status_data.get('gpu_used') else "‚ùå")
                st.metric("‚è±Ô∏è Tiempo", f"{status_data.get('total_time_seconds', 0):.1f}s" if status_data.get('total_time_seconds') else 'N/A')
            
            # Mostrar detalles adicionales
            if status_data.get('status') == 'completed':
                st.success("üéâ ¬°Evaluaci√≥n completada! Puedes ver los resultados en la p√°gina de resultados.")
                
                # Results button removed per user request
                st.info("Results button removed per user request")
                    
            elif status_data.get('status') == 'running':
                st.info("‚è≥ Evaluaci√≥n en progreso... Verifica nuevamente en unos minutos.")
                
            elif status_data.get('status') == 'error':
                st.error("‚ùå Error en la evaluaci√≥n. Revisa los logs de Colab.")
                
        else:
            st.warning("‚ö†Ô∏è No se pudo verificar el estado. Aseg√∫rate de que Google Drive est√© configurado correctamente.")


if __name__ == "__main__":
    show_cumulative_metrics_create_page()