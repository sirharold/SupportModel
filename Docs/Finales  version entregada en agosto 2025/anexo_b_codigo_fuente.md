# B. CÃ“DIGO FUENTE PRINCIPAL

## B.1 Repositorio del Proyecto

El cÃ³digo fuente completo del sistema RAG para recuperaciÃ³n semÃ¡ntica de documentaciÃ³n tÃ©cnica de Microsoft Azure estÃ¡ disponible en el repositorio de GitHub del proyecto.

### B.1.1 UbicaciÃ³n del Repositorio

**Repositorio GitHub:** https://github.com/sirharold/SupportModel

El repositorio es pÃºblico y contiene todo el cÃ³digo fuente, documentaciÃ³n, datasets y resultados experimentales utilizados en esta investigaciÃ³n.

### B.1.2 Estructura del Repositorio

El repositorio contiene la implementaciÃ³n completa del sistema, organizada en los siguientes directorios principales:

```
SupportModel/
â”œâ”€â”€ src/                          # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ apps/                     # Aplicaciones Streamlit modulares
â”‚   â”œâ”€â”€ core/                     # Componentes centrales del sistema
â”‚   â”‚   â”œâ”€â”€ qa_pipeline.py        # Pipeline principal de Q&A
â”‚   â”‚   â””â”€â”€ reranker.py           # Reranking con CrossEncoder
â”‚   â”œâ”€â”€ data/                     # Procesamiento de datos
â”‚   â”‚   â”œâ”€â”€ embedding.py          # GestiÃ³n de modelos de embedding
â”‚   â”‚   â”œâ”€â”€ processing.py         # Procesamiento de documentos
â”‚   â”‚   â””â”€â”€ extract_links.py      # ExtracciÃ³n de enlaces
â”‚   â”œâ”€â”€ evaluation/               # Framework de evaluaciÃ³n
â”‚   â”‚   â”œâ”€â”€ metrics/              # MÃ©tricas especializadas
â”‚   â”‚   â””â”€â”€ comparison.py         # ComparaciÃ³n de modelos
â”‚   â”œâ”€â”€ services/                 # Servicios del sistema
â”‚   â”‚   â”œâ”€â”€ auth/                 # AutenticaciÃ³n APIs
â”‚   â”‚   â”œâ”€â”€ storage/              # ChromaDB y almacenamiento
â”‚   â”‚   â””â”€â”€ answer_generation/    # GeneraciÃ³n de respuestas RAG
â”‚   â””â”€â”€ ui/                       # Interfaces de usuario
â”œâ”€â”€ Docs/                         # DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ Finales/                  # DocumentaciÃ³n final de tesis
â”‚   â”‚   â”œâ”€â”€ capitulo_*.md         # CapÃ­tulos de la tesis
â”‚   â”‚   â”œâ”€â”€ anexo_*.md            # Anexos detallados
â”‚   â”‚   â””â”€â”€ Contenidos.md         # Tabla de contenidos
â”‚   â”œâ”€â”€ Analisis/                 # Scripts de anÃ¡lisis
â”‚   â”‚   â”œâ”€â”€ analyze_metrics_v2.py # AnÃ¡lisis de mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ verify_*_statistics.py # VerificaciÃ³n de estadÃ­sticas
â”‚   â”‚   â””â”€â”€ wilcoxon_*.py         # Tests estadÃ­sticos
â”‚   â””â”€â”€ README.md                 # DocumentaciÃ³n de estructura
â”œâ”€â”€ colab_data/                   # Notebooks de Google Colab
â”‚   â”œâ”€â”€ Cumulative_Ticket_Evaluation.ipynb  # Notebook principal
â”‚   â”œâ”€â”€ lib/                      # LibrerÃ­as modulares para Colab
â”‚   â””â”€â”€ *.parquet                 # Embeddings pre-calculados (ignorados)
â”œâ”€â”€ external_helpers/             # Scripts auxiliares
â”‚   â”œâ”€â”€ check_chromadb_*.py       # VerificaciÃ³n de ChromaDB
â”‚   â”œâ”€â”€ create_questions_*.py     # PoblaciÃ³n de colecciones
â”‚   â””â”€â”€ verify_questions_*.py     # ValidaciÃ³n de datos
â”œâ”€â”€ tests/                        # Tests unitarios
â”œâ”€â”€ data/                         # Datos experimentales
â”‚   â”œâ”€â”€ train_set.json            # Dataset de entrenamiento
â”‚   â”œâ”€â”€ val_set.json              # Dataset de validaciÃ³n
â”‚   â””â”€â”€ ground_truth_links.csv    # Ground truth para evaluaciÃ³n
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ .gitignore                    # Archivos ignorados por Git
â””â”€â”€ ARCHIVOS_IGNORADOS.md         # DocumentaciÃ³n de archivos ignorados
```

### B.1.3 Componentes Principales

#### B.1.3.1 Pipeline Principal (`src/core/`)
- **`qa_pipeline.py`**: Pipeline principal de pregunta-respuesta con mÃ©tricas
- **`reranker.py`**: CrossEncoder con normalizaciÃ³n sigmoid para reranking

#### B.1.3.2 Procesamiento de Datos (`src/data/`)
- **`embedding.py`**: GestiÃ³n de mÃºltiples modelos de embedding (Ada, MPNet, MiniLM, E5-Large)
- **`processing.py`**: SegmentaciÃ³n y limpieza de documentos tÃ©cnicos
- **`extract_links.py`**: ExtracciÃ³n y normalizaciÃ³n de enlaces de ground truth

#### B.1.3.3 Framework de EvaluaciÃ³n (`src/evaluation/`)
- **`metrics/`**: MÃ³dulos especializados para mÃ©tricas de recuperaciÃ³n y RAG
- **`comparison.py`**: ComparaciÃ³n sistemÃ¡tica entre modelos de embedding

#### B.1.3.4 Servicios del Sistema (`src/services/`)
- **`storage/chromadb_utils.py`**: Utilidades para ChromaDB y gestiÃ³n vectorial
- **`answer_generation/ragas_evaluation.py`**: EvaluaciÃ³n RAG con RAGAS framework
- **`auth/`**: GestiÃ³n de autenticaciÃ³n para APIs (OpenAI, Google)

#### B.1.3.5 Aplicaciones Streamlit (`src/apps/`)
- **`cumulative_metrics_results_matplotlib.py`**: VisualizaciÃ³n de resultados experimentales
- **`comparison_page.py`**: ComparaciÃ³n interactiva de modelos
- **`main_qa_app.py`**: Interfaz principal de consultas

#### B.1.3.6 DocumentaciÃ³n Organizada (`Docs/`)
- **`Finales/`**: DocumentaciÃ³n final de la tesis (capÃ­tulos y anexos)
- **`Analisis/`**: Scripts de anÃ¡lisis y verificaciÃ³n estadÃ­stica
- **`README.md`**: DocumentaciÃ³n de la estructura del proyecto

#### B.1.3.7 Scripts de AnÃ¡lisis (`Docs/Analisis/`)
- **`analyze_metrics_v2.py`**: AnÃ¡lisis comprehensivo de mÃ©tricas de rendimiento
- **`verify_document_statistics.py`**: VerificaciÃ³n de estadÃ­sticas del corpus
- **`wilcoxon_detailed_analysis.py`**: Tests estadÃ­sticos de significancia

#### B.1.3.8 Notebooks Experimentales (`colab_data/`)
- **`Cumulative_Ticket_Evaluation.ipynb`**: Notebook principal de evaluaciÃ³n experimental
- **`lib/`**: LibrerÃ­as modulares para evaluaciÃ³n en Google Colab
- ImplementaciÃ³n completa del pipeline de evaluaciÃ³n multi-modelo

#### B.1.3.9 Resultados Experimentales
- **`cumulative_results_20250802_222752.json`**: Archivo principal de resultados experimentales
  - EvaluaciÃ³n completa de 4,000 consultas (1,000 por modelo)
  - MÃ©tricas detalladas antes y despuÃ©s de reranking
  - ValidaciÃ³n estadÃ­stica con tests de significancia
  - Datos de la evaluaciÃ³n experimental definitiva del 2 de agosto de 2025

### B.1.4 TecnologÃ­as y Dependencias

El proyecto utiliza las siguientes tecnologÃ­as principales:

- **Python 3.8+**: Lenguaje de programaciÃ³n principal
- **ChromaDB 0.5.23**: Base de datos vectorial
- **Sentence-Transformers 5.0.0**: Modelos de embedding
- **OpenAI API 1.93.0**: Modelo Ada y evaluaciÃ³n RAG
- **Streamlit 1.46.1**: Interfaz de usuario web
- **Transformers 4.44.0**: Arquitecturas de modelos de lenguaje

### B.1.5 Reproducibilidad

El repositorio incluye:

1. **ConfiguraciÃ³n de ambiente** completa (`requirements.txt`)
2. **Scripts de verificaciÃ³n** para validar configuraciÃ³n
3. **Datasets de entrenamiento y validaciÃ³n** (`data/train_set.json`, `data/val_set.json`)
4. **Ground truth validado** (`data/ground_truth_links.csv`)
5. **Resultados experimentales completos** (`cumulative_results_20250802_222752.json`)
6. **DocumentaciÃ³n detallada** de instalaciÃ³n y uso
7. **Notebooks ejecutables** en Google Colab

### B.1.6 Instrucciones de Acceso

Para acceder al cÃ³digo fuente completo:

1. **Clonar el repositorio:**
   ```bash
   git clone https://github.com/sirharold/SupportModel.git
   cd SupportModel
   ```

2. **Configurar el ambiente:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Ejecutar la aplicaciÃ³n:**
   ```bash
   streamlit run src/apps/main_qa_app.py
   ```

### B.1.7 Licencia y TÃ©rminos de Uso

El cÃ³digo fuente se distribuye bajo los tÃ©rminos establecidos para investigaciÃ³n acadÃ©mica, con las siguientes consideraciones:

- **Uso acadÃ©mico**: Permitido para investigaciÃ³n y educaciÃ³n
- **Datos de Microsoft**: Sujeto a tÃ©rminos de uso de Microsoft Learn
- **Modelos propietarios**: OpenAI Ada requiere API key vÃ¡lida
- **AtribuciÃ³n**: Citar apropiadamente en trabajos derivados

### B.1.8 Contacto y Soporte

Para consultas sobre el cÃ³digo fuente, implementaciÃ³n o extensiones:

- **Autor**: Harold GÃ³mez
- **InstituciÃ³n**: [InstituciÃ³n acadÃ©mica]
- **Email**: [Email de contacto]

### B.1.9 Acceso PÃºblico y Transparencia

El repositorio es completamente **pÃºblico y accesible** en GitHub:

**ğŸ”— URL Directa:** https://github.com/sirharold/SupportModel

**Contenido disponible pÃºblicamente:**
- âœ… Todo el cÃ³digo fuente sin restricciones
- âœ… Datasets de entrenamiento y validaciÃ³n completos
- âœ… Resultados experimentales de la evaluaciÃ³n con 4,000 consultas
- âœ… DocumentaciÃ³n completa de la investigaciÃ³n
- âœ… Notebooks ejecutables de Google Colab
- âœ… Scripts de anÃ¡lisis estadÃ­stico y verificaciÃ³n

Esta disponibilidad pÃºblica permite la **replicaciÃ³n completa** de todos los experimentos y resultados reportados en esta investigaciÃ³n, cumpliendo con los estÃ¡ndares de reproducibilidad cientÃ­fica.

### B.1.10 Nota sobre Versiones

El cÃ³digo corresponde a la versiÃ³n utilizada para la evaluaciÃ³n experimental reportada en este trabajo (agosto 2025). Los resultados experimentales definitivos se obtuvieron el 2 de agosto de 2025 con 1,000 consultas por modelo. Versiones posteriores pueden incluir mejoras y optimizaciones adicionales basadas en los hallazgos de esta investigaciÃ³n.