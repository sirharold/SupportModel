# ğŸ”¬ Diagrama de Flujo: PÃ¡gina de ComparaciÃ³n de Modelos Azure Q&A System

## Flujo Completo del Sistema de ComparaciÃ³n de Modelos

```mermaid
flowchart TD
    A[ğŸš€ Inicio: Usuario en PÃ¡gina de ComparaciÃ³n] --> B[ğŸ“‹ Cargar preguntas de ejemplo]
    
    B --> B1{ğŸ“š Preguntas ya cargadas en session_state?}
    B1 -->|SÃ­| B2[âœ… Usar preguntas existentes]
    B1 -->|No| B3[ğŸŒ WEAVIATE: get_sample_questions]
    
    B3 --> B4[ğŸ”— Filtrar preguntas con enlaces MS Learn]
    B4 --> B5[ğŸ’¾ Guardar en session_state]
    B5 --> B2
    
    B2 --> C[ğŸ“ Usuario selecciona pregunta del dropdown]
    C --> D[âš™ï¸ Configurar parÃ¡metros]
    
    D --> D1[ğŸ”§ Ajustar top_k slider 5-20]
    D1 --> D2[ğŸ”„ Toggle reranking con LLM]
    D2 --> D3{ğŸ§ª Habilitar mÃ©tricas avanzadas?}
    
    D3 -->|SÃ­| D4[âœ… Activar advanced metrics]
    D3 -->|No| D5[ğŸ“Š Solo mÃ©tricas bÃ¡sicas]
    
    D4 --> D6{ğŸ¤– Generar respuestas para evaluaciÃ³n?}
    D6 -->|SÃ­| D7[âœ… Habilitar generaciÃ³n RAG]
    D6 -->|No| D8[ğŸ“„ Solo documentos]
    
    D5 --> D8
    D7 --> E[ğŸ” Click Comparar Modelos]
    D8 --> E
    
    E --> F[ğŸ”§ Inicializar comparison_results]
    F --> G[ğŸ“Š Configurar progress tracking]
    G --> H[ğŸ”„ BUCLE: Para cada modelo embedding]
    
    %% Bucle principal para cada modelo
    H --> H1[ğŸ“Œ Modelo actual: multi-qa-mpnet-base-dot-v1]
    H1 --> H2[â±ï¸ Iniciar timer modelo]
    H2 --> H3[ğŸ”§ initialize_clients para modelo actual]
    
    H3 --> H3a[ğŸŒ Conectar Weaviate para modelo]
    H3a --> H3b[ğŸ¤– Inicializar embedding_client especÃ­fico]
    H3b --> H3c[ğŸ”‘ Inicializar OpenAI client]
    H3c --> H3d[ğŸ’ Inicializar Gemini client]
    H3d --> H3e[ğŸ¦™ Inicializar Local Llama client]
    H3e --> H3f[ğŸ¤– Inicializar Local Mistral client]
    
    H3f --> H4{ğŸ§ª MÃ©tricas avanzadas habilitadas?}
    
    %% Pipeline con mÃ©tricas avanzadas
    H4 -->|SÃ­| H5[ğŸ“ evaluate_rag_with_advanced_metrics]
    H4 -->|No| H6[ğŸ“ answer_question_documents_only]
    
    H5 --> H5a[ğŸ” refine_and_prepare_query]
    H5a --> H5b[ğŸ§® Generar embedding de query]
    H5b --> H5c[ğŸŒ WEAVIATE: BÃºsqueda vectorial]
    H5c --> H5d[ğŸ”„ Aplicar reranking]
    H5d --> H5e[ğŸ¤– Generar respuesta con modelo seleccionado]
    H5e --> H5f[ğŸ§ª Calcular mÃ©tricas avanzadas RAG]
    
    H5f --> H5f1[ğŸš« calculate_hallucination_score]
    H5f1 --> H5f2[ğŸ¯ calculate_context_utilization]
    H5f2 --> H5f3[âœ… calculate_completeness_score]
    H5f3 --> H5f4[ğŸ˜Š calculate_satisfaction_score]
    
    H5f4 --> H7[ğŸ“ answer_question_documents_only para UI]
    H7 --> H8[ğŸ“„ Extraer documentos para display]
    
    %% Pipeline estÃ¡ndar
    H6 --> H6a[ğŸ” refine_and_prepare_query]
    H6a --> H6b[ğŸ§® Generar embedding de query]
    H6b --> H6c[ğŸŒ WEAVIATE: BÃºsqueda vectorial]
    H6c --> H6d[ğŸ”„ Aplicar reranking]
    H6d --> H8
    
    H8 --> H9[ğŸ¤– generate_summary con Mistral local]
    H9 --> H10[ğŸ“Š calculate_content_metrics]
    H10 --> H11[â±ï¸ Calcular elapsed_time]
    H11 --> H12[ğŸ’¾ Guardar resultados en session_state]
    
    H12 --> H13{ğŸ”„ MÃ¡s modelos por procesar?}
    H13 -->|SÃ­| H14[ğŸ“Œ Siguiente modelo: all-MiniLM-L6-v2]
    H13 -->|No| I[âœ… Todos los modelos procesados]
    
    H14 --> H15[ğŸ“Š Actualizar progress bar]
    H15 --> H2
    
    %% Procesamiento de resultados
    I --> I1[ğŸ“Š Calcular performance data]
    I1 --> I2[ğŸ”¢ Calcular latencia por modelo]
    I2 --> I3[âš¡ Calcular throughput estimado]
    I3 --> I4[ğŸ“ˆ Calcular score promedio y desviaciÃ³n]
    I4 --> I5[ğŸ“Š Calcular mÃ©tricas de consistencia]
    I5 --> I6[ğŸ“„ generate_pdf_report]
    
    I6 --> J[ğŸ¨ Renderizar UI de resultados]
    J --> J1[ğŸ“‹ Mostrar botÃ³n descarga PDF]
    J1 --> J2[ğŸ“Š Crear columnas para cada modelo]
    
    J2 --> J3[ğŸ”„ BUCLE: Para cada modelo]
    J3 --> J4[ğŸ“Œ Renderizar informaciÃ³n modelo]
    J4 --> J5[ğŸ“Š Mostrar mÃ©tricas bÃ¡sicas]
    J5 --> J6[ğŸ“‹ Mostrar resumen IA]
    J6 --> J7[ğŸ”„ BUCLE: Para cada documento]
    
    J7 --> J8[ğŸ¨ Aplicar color coding por score]
    J8 --> J9[âœ… Marcar ground truth links]
    J9 --> J10[ğŸ”„ Marcar documentos duplicados]
    J10 --> J11[ğŸ¨ Renderizar card HTML]
    J11 --> J12{ğŸ”„ MÃ¡s documentos?}
    
    J12 -->|SÃ­| J7
    J12 -->|No| J13{ğŸ”„ MÃ¡s modelos?}
    J13 -->|SÃ­| J3
    J13 -->|No| K[ğŸ“Š Mostrar mÃ©tricas de rendimiento]
    
    %% SecciÃ³n de mÃ©tricas y visualizaciones
    K --> K1[ğŸ“ˆ Crear grÃ¡fico de latencia]
    K1 --> K2[âš¡ Crear grÃ¡fico de throughput]
    K2 --> K3[ğŸ“Š Crear distribuciÃ³n de scores]
    K3 --> K4[ğŸ“Š Crear mÃ©tricas de consistencia]
    K4 --> K5[ğŸ“ˆ Crear grÃ¡fico calidad vs variabilidad]
    
    K5 --> L[ğŸ“Š Mostrar mÃ©tricas de calidad de contenido]
    L --> L1[ğŸ¨ Aplicar color coding BERTScore/ROUGE]
    L1 --> L2[ğŸ“‹ Renderizar tabla styled con colores]
    
    L2 --> M[ğŸ“Š Mostrar tabla mÃ©tricas de rendimiento]
    M --> M1[ğŸ¨ Aplicar color coding performance]
    M1 --> M2[ğŸ“‹ Renderizar tabla styled con umbrales]
    
    M2 --> N{ğŸ§ª Hay mÃ©tricas avanzadas RAG?}
    N -->|SÃ­| O[ğŸ“Š Mostrar tabla mÃ©tricas avanzadas RAG]
    N -->|No| P[ğŸ“‹ Mostrar guÃ­a de mÃ©tricas]
    
    O --> O1[ğŸ¨ Aplicar color coding advanced metrics]
    O1 --> O2[ğŸš« Color alucinaciÃ³n verde=bajo]
    O2 --> O3[ğŸ¯ Color utilizaciÃ³n verde=alto]
    O3 --> O4[âœ… Color completitud verde=alto]
    O4 --> O5[ğŸ˜Š Color satisfacciÃ³n verde=alto]
    O5 --> O6[ğŸ“‹ Renderizar tabla advanced styled]
    
    O6 --> P
    P --> P1[ğŸ“‹ Crear tabla consolidada de mÃ©tricas]
    P1 --> P2[ğŸ’¡ Crear expandibles con tooltips]
    P2 --> P3[ğŸ“– Mostrar fÃ³rmulas y referencias APA]
    P3 --> P4[ğŸ¯ Mostrar umbrales por mÃ©trica]
    P4 --> Q[âœ… Fin del proceso de comparaciÃ³n]
    
    %% Servicios Externos destacados
    B3:::external
    H3a:::external
    H5c:::external
    H6c:::external
    
    %% Decisiones destacadas  
    B1:::decision
    D3:::decision
    D6:::decision
    H4:::decision
    H13:::decision
    J12:::decision
    J13:::decision
    N:::decision
    
    %% Procesos locales destacados
    H3b:::local
    H3e:::local
    H3f:::local
    H5a:::local
    H5b:::local
    H5f1:::local
    H5f2:::local
    H5f3:::local
    H5f4:::local
    H6a:::local
    H6b:::local
    H9:::local
    H10:::local
    
    %% Estilos CSS
    classDef external fill:#ffcccc,stroke:#ff6666,stroke-width:3px,color:#000
    classDef decision fill:#fff2cc,stroke:#d6b656,stroke-width:2px,color:#000
    classDef local fill:#d4edda,stroke:#28a745,stroke-width:2px,color:#000
```

## ğŸ”§ Leyenda de Componentes

### ğŸŒ Servicios Externos (Rojo)
- **Weaviate Cloud**: Base de datos vectorial externa
  - `get_sample_questions`: Obtener preguntas de ejemplo para testing
  - `BÃºsqueda vectorial`: Buscar documentos en cada modelo especÃ­fico
  - Cada modelo tiene su propia clase: `DocumentsMpnet`, `DocumentsMiniLM`, `Documentation`

### ğŸ’š Procesos Locales (Verde)
- **Embedding local**: sentence-transformers para cada modelo
- **CrossEncoder local**: ms-marco-MiniLM-L-6-v2 para reranking
- **Llama 3.1 8B**: GeneraciÃ³n local de respuestas
- **Mistral 7B**: GeneraciÃ³n local de resÃºmenes
- **MÃ©tricas avanzadas RAG**: CÃ¡lculos locales de alucinaciÃ³n, utilizaciÃ³n, etc.
- **Content metrics**: BERTScore y ROUGE calculados localmente

### ğŸŸ¡ Puntos de DecisiÃ³n (Amarillo)
- **MÃ©tricas avanzadas**: Determina pipeline completo vs estÃ¡ndar
- **Generar respuestas**: Activa generaciÃ³n RAG para evaluaciÃ³n
- **MÃ¡s modelos**: Control del bucle principal de comparaciÃ³n
- **Hay mÃ©tricas avanzadas**: Determina si mostrar tabla avanzada

## ğŸ“Š MÃ©tricas y Tiempos por Modelo

### âš¡ Tiempos Estimados por Modelo
- **Carga inicial de preguntas**: 2-5s (una vez)
- **Por modelo embedding (estÃ¡ndar)**: 1-3s
- **Por modelo embedding (con RAG)**: 5-15s
- **Por modelo embedding (con advanced metrics)**: 10-25s
- **GeneraciÃ³n de visualizaciones**: 1-2s

### ğŸ“ˆ Optimizaciones de Costo
- **Modelos locales por defecto**: Llama + Mistral para generaciÃ³n
- **Reranking local**: CrossEncoder instead of GPT-4
- **Embeddings locales**: sentence-transformers
- **MÃ©tricas locales**: BERTScore y ROUGE calculados localmente

## ğŸ”„ Flujos Alternativos

### ğŸš€ Modo BÃ¡sico (Sin MÃ©tricas Avanzadas)
```
Usuario â†’ SelecciÃ³n â†’ ConfiguraciÃ³n â†’ Bucle modelos â†’ Weaviate â†’ Documentos â†’ MÃ©tricas bÃ¡sicas â†’ UI
```

### ğŸ§  Modo Completo (Con MÃ©tricas Avanzadas)
```
Usuario â†’ SelecciÃ³n â†’ ConfiguraciÃ³n â†’ Bucle modelos â†’ RAG pipeline â†’ Advanced metrics â†’ Documentos â†’ UI completa
```

### ğŸ’° Modo Costo Cero
```
Todo local: Mistral summaries + Local embeddings + CrossEncoder + Llama generation + Local metrics
```

## ğŸ¨ Renderizado y Visualizaciones

### ğŸ“Š GrÃ¡ficos Interactivos (Plotly)
- **Latencia por modelo**: Barra horizontal con tiempo total
- **Throughput estimado**: Consultas por segundo con factor overhead
- **DistribuciÃ³n de scores**: Box plot mostrando calidad y consistencia
- **Consistencia**: MÃ©trica de uniformidad en resultados
- **Calidad vs Variabilidad**: Scatter plot con tamaÃ±o por docs recuperados

### ğŸ¨ Color Coding System
- **Performance metrics**: Verde (excelente) â†’ Amarillo (bueno) â†’ Rojo (necesita mejora)
- **Advanced RAG metrics**: Sistema especÃ­fico por mÃ©trica
  - ğŸš« AlucinaciÃ³n: Verde (bajo) â†’ Rojo (alto)
  - ğŸ¯ UtilizaciÃ³n: Verde (alto) â†’ Rojo (bajo)
  - âœ… Completitud: Verde (alto) â†’ Rojo (bajo)
  - ğŸ˜Š SatisfacciÃ³n: Verde (alto) â†’ Rojo (bajo)

### ğŸ“‹ Tablas Interactivas
- **Styled DataFrames**: Color coding automÃ¡tico basado en umbrales
- **Tooltips expandibles**: Detalles de fÃ³rmulas y referencias APA
- **Responsive design**: Adaptable a diferentes tamaÃ±os de pantalla

## ğŸ§ª MÃ©tricas Avanzadas Pipeline

### ğŸ”„ Flujo de EvaluaciÃ³n Avanzada
1. **evaluate_rag_with_advanced_metrics** ejecuta pipeline completo
2. **MÃ©tricas calculadas en paralelo**:
   - ğŸš« DetecciÃ³n de alucinaciones (entity extraction + fact checking)
   - ğŸ¯ UtilizaciÃ³n de contexto (document coverage + phrase utilization)
   - âœ… Completitud de respuesta (component analysis por tipo de pregunta)
   - ğŸ˜Š SatisfacciÃ³n del usuario (clarity + directness + actionability)
3. **IntegraciÃ³n con mÃ©tricas tradicionales**: BERTScore, ROUGE, performance

### ğŸ“Š ComparaciÃ³n Multi-Modelo
- **EvaluaciÃ³n paralela**: Todos los modelos embedding testados simultÃ¡neamente
- **MÃ©tricas comparativas**: Ranking automÃ¡tico por performance
- **Ground truth validation**: ComparaciÃ³n con enlaces Microsoft Learn reales
- **Duplicate detection**: IdentificaciÃ³n de documentos comunes entre modelos