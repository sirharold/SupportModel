# ABSTRACT

This research develops and evaluates a semantic retrieval system for specialized technical information based on RAG (Retrieval-Augmented Generation) architectures, using Microsoft Azure documentation as a case study. The work addresses the problem of technical knowledge accessibility where traditional lexical search systems present significant limitations in specialized domains. The research systematically compares four embedding models —Ada (OpenAI), MPNet, E5-Large, and MiniLM— evaluating their performance in vector retrieval and after applying neural reranking with CrossEncoder. The system stores over 800,000 vectors in ChromaDB, processing a corpus of 187,031 documentation chunks from 62,417 unique Microsoft Learn documents, using 2,067 validated question-document pairs as ground truth.

Results establish a performance hierarchy: Ada achieves Precision@5 of 0.098, surpassing MPNet (0.070), E5-Large (0.065), and MiniLM (0.053), with relative differences of 28-46%. MPNet achieves 71% of Ada's performance using only 50% of dimensions (768 vs 1,536), representing a favorable trade-off for resource-constrained applications. Reranking analysis reveals a robust differential pattern: CrossEncoder improves weak models (MiniLM +13.6%) but degrades optimized models (Ada -16.7%), establishing that reranking application must be selective according to the embedding model used.

Multi-metric evaluation identifies a critical discrepancy: while traditional retrieval metrics show low values (Precision@5 < 0.10), semantic metrics reveal superior performance (Faithfulness 0.69-0.73, BERTScore 0.54-0.62), suggesting that all models produce comparable semantic quality responses. This discrepancy evidences the main methodological limitation: ground truth based on community links does not guarantee validity of question-document correspondence, preventing conclusions about absolute performance while allowing valid relative comparisons between models.

Methodological contributions include systematic documentation of limitations in automated ground truth construction, a multi-metric evaluation framework combining traditional metrics with RAGAS and BERTScore, and validation of the differential reranking pattern. Technical contributions comprise a reference implementation for vector storage with ChromaDB (latency < 100ms, 800,000+ vectors) and a reproducible automated evaluation pipeline. The work establishes as main recommendation the development of expert-validated ground truth from the technical domain, with recommended extensions in hybrid search, multi-modal processing, and cross-domain validation in other cloud ecosystems (AWS, GCP).

**Keywords:** Semantic Information Retrieval, RAG, Embeddings, Neural Reranking, Technical Support, ChromaDB, RAGAS, BERTScore, Microsoft Azure
