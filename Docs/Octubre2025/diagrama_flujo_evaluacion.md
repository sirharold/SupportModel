# Diagrama de Flujo - Pipeline de EvaluaciÃ³n RAG

## Diagrama del Proceso Completo de EvaluaciÃ³n

```mermaid
flowchart TB
    %% Estilos
    classDef setupStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#0d47a1
    classDef configStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#e65100
    classDef processStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c
    classDef loopStyle fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#1b5e20
    classDef metricsStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#880e4f
    classDef ragStyle fill:#e0f7fa,stroke:#0097a7,stroke-width:2px,color:#006064
    classDef outputStyle fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#f57f17
    classDef decisionStyle fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#b71c1c

    %% FASE 1: PREPARACIÃ“N
    START([ğŸš€ INICIO]):::setupStyle
    START --> SETUP[FASE 1: PREPARACIÃ“N<br/>ğŸ“¦ InstalaciÃ³n de librerÃ­as<br/>ğŸ”Œ ConexiÃ³n Google Drive<br/>ğŸ¤– Carga de modelos]:::setupStyle

    %% FASE 2: CONFIGURACIÃ“N
    SETUP --> CONFIG[FASE 2: CONFIGURACIÃ“N<br/>ğŸ“„ Lectura archivo config<br/>â“ Carga de preguntas validadas<br/>âš™ï¸ ParÃ¡metros top-k y reranking]:::configStyle

    CONFIG --> LOADDATA[Carga de Embeddings<br/>ğŸ“Š 4 archivos Parquet<br/>ğŸ”¢ 187,031 vectores por modelo<br/>ğŸ“ Metadatos documentos]:::configStyle

    %% FASE 3: LOOP POR MODELO
    LOADDATA --> MODELLOOP{Para cada modelo<br/>Ada, E5-Large<br/>MPNet, MiniLM}:::loopStyle

    %% FASE 4: LOOP POR PREGUNTA
    MODELLOOP -->|Siguiente modelo| QLOOP{Para cada pregunta<br/>en configuraciÃ³n}:::loopStyle

    %% GeneraciÃ³n de embedding de consulta
    QLOOP -->|Siguiente pregunta| GENEMB[GeneraciÃ³n Embedding Consulta<br/>ğŸ”¤ Pregunta â†’ Vector<br/>ğŸ“ DimensiÃ³n segÃºn modelo<br/>OpenAI API para Ada<br/>SentenceTransformers para otros]:::processStyle

    %% BÃºsqueda por similitud
    GENEMB --> SEARCH[BÃšSQUEDA VECTORIAL<br/>ğŸ“Š Similitud coseno<br/>ğŸ” vs 187,031 documentos<br/>ğŸ“ˆ Ordenamiento descendente]:::processStyle

    %% RecuperaciÃ³n de top-k
    SEARCH --> TOPK[RecuperaciÃ³n Top-K<br/>ğŸ“‹ Top-15 documentos<br/>ğŸ”— Links, tÃ­tulos, contenido<br/>ğŸ’¯ Scores de similitud coseno]:::processStyle

    %% MÃ©tricas PRE-RERANKING
    TOPK --> PREKLOOP{Para cada k<br/>1, 3, 5, 10, 15}:::loopStyle

    PREKLOOP --> PREMETRICS[CÃLCULO MÃ‰TRICAS @k PRE-RERANKING<br/>âœ“ Precision@k<br/>âœ“ Recall@k<br/>âœ“ F1@k<br/>âœ“ NDCG@k<br/>âœ“ MAP@k<br/>âœ“ MRR@k]:::metricsStyle

    PREMETRICS --> PREKLOOP
    PREKLOOP -->|Completado| STOREPRE[ğŸ’¾ Almacenar mÃ©tricas<br/>PRE-reranking]:::metricsStyle

    %% RERANKING CON CROSSENCODER
    STOREPRE --> RERANK[RERANKING CROSSENCODER<br/>ğŸ§  Modelo: mxbai-rerank-xsmall-v1<br/>ğŸ“Š Procesamiento tÃ­tulo + contenido<br/>ğŸ¯ Scores de relevancia]:::processStyle

    RERANK --> NORMALIZE[NormalizaciÃ³n Min-Max<br/>ğŸ“ Scores entre 0 y 1<br/>ğŸ”„ Reordenamiento final]:::processStyle

    %% MÃ©tricas POST-RERANKING
    NORMALIZE --> POSTKLOOP{Para cada k<br/>1, 3, 5, 10, 15}:::loopStyle

    POSTKLOOP --> POSTMETRICS[CÃLCULO MÃ‰TRICAS @k POST-RERANKING<br/>âœ“ Precision@k<br/>âœ“ Recall@k<br/>âœ“ F1@k<br/>âœ“ NDCG@k<br/>âœ“ MAP@k<br/>âœ“ MRR@k<br/>âœ“ CrossEncoder Score]:::metricsStyle

    POSTMETRICS --> POSTKLOOP
    POSTKLOOP -->|Completado| STOREPOST[ğŸ’¾ Almacenar mÃ©tricas<br/>POST-reranking]:::metricsStyle

    %% MÃ‰TRICAS RAG
    STOREPOST --> GENANS[GeneraciÃ³n de Respuesta<br/>ğŸ’¬ GPT-3.5-turbo<br/>ğŸ“ Contexto: Top-3 documentos<br/>ğŸ² Temperature=0 determinÃ­stico]:::ragStyle

    GENANS --> RAGMETRICS[MÃ‰TRICAS RAGAS<br/>ğŸ“Š Single API call combinada<br/>âœ“ Faithfulness 1-5<br/>âœ“ Answer Relevancy 1-5<br/>âœ“ Answer Correctness 1-5<br/>âœ“ Context Precision 1-5<br/>âœ“ Context Recall 1-5<br/>ğŸ”„ NormalizaciÃ³n 0 a 1]:::ragStyle

    RAGMETRICS --> BERTSCORE[MÃ‰TRICAS BERTSCORE<br/>ğŸ“ Modelo: DeBERTa-base-mnli<br/>âœ“ Precision semÃ¡ntica<br/>âœ“ Recall semÃ¡ntico<br/>âœ“ F1 semÃ¡ntico<br/>ğŸ”— Semantic Similarity MPNet]:::ragStyle

    BERTSCORE --> STORERAG[ğŸ’¾ Almacenar mÃ©tricas RAG]:::ragStyle

    %% Continuar loop
    STORERAG --> QLOOP

    %% Fin del loop de preguntas
    QLOOP -->|Todas evaluadas| AVGMETRICS[CÃ¡lculo de Promedios<br/>ğŸ“Š AgregaciÃ³n de mÃ©tricas<br/>ğŸ“ˆ EstadÃ­sticas del modelo<br/>ğŸ’¯ Tasas de Ã©xito]:::processStyle

    AVGMETRICS --> MODELLOOP

    %% Fin del loop de modelos y guardado
    MODELLOOP -->|Todos evaluados| SAVERESULTS[GUARDADO DE RESULTADOS<br/>ğŸ“¦ Estructura JSON compatible Streamlit<br/>ğŸ’¾ cumulative_results_YYYYMMDD_HHMMSS.json<br/>ğŸ• Timestamp zona Chile<br/>ğŸ“Š MÃ©tricas por modelo y agregadas<br/>ğŸ”¬ Metadata de verificaciÃ³n]:::outputStyle

    SAVERESULTS --> END([ğŸ‰ FIN]):::setupStyle
```

## DescripciÃ³n de las Fases

### ğŸš€ FASE 1: PREPARACIÃ“N (Setup)
- InstalaciÃ³n y carga de librerÃ­as necesarias (PyTorch, sentence-transformers, OpenAI, etc.)
- ConexiÃ³n a Google Drive para acceso a datos
- Carga de API keys (OpenAI, HuggingFace)
- InicializaciÃ³n de modelos de embeddings y CrossEncoder
- ConfiguraciÃ³n de cache para OpenAI API

### âš™ï¸ FASE 2: CONFIGURACIÃ“N
- Lectura del archivo de configuraciÃ³n JSON mÃ¡s reciente
- Carga de preguntas con ground truth validado
- ObtenciÃ³n de parÃ¡metros de evaluaciÃ³n (top-k, mÃ©todo reranking)
- ValidaciÃ³n de disponibilidad de modelos
- Carga de embeddings precomputados desde archivos Parquet

### ğŸ”„ FASE 3: LOOP POR MODELO
Para cada modelo (Ada, E5-Large, MPNet, MiniLM):
- Procesamiento independiente de todas las preguntas
- GeneraciÃ³n de mÃ©tricas especÃ­ficas del modelo

### â“ FASE 4: LOOP POR PREGUNTA
Para cada pregunta del dataset:

#### 4.1 BÃºsqueda Vectorial (Similitud Coseno)
- GeneraciÃ³n de embedding de la pregunta usando el modelo actual
- CÃ¡lculo de similitud coseno vs. 187,031 documentos indexados
- RecuperaciÃ³n de Top-K=15 documentos mÃ¡s similares

#### 4.2 MÃ©tricas PRE-Reranking
Ciclo para k âˆˆ {1, 3, 5, 10, 15}:
- **Precision@k**: ProporciÃ³n de relevantes en top-k
- **Recall@k**: ProporciÃ³n de relevantes totales capturados
- **F1@k**: Media armÃ³nica de Precision y Recall
- **NDCG@k**: Ganancia acumulada descontada normalizada
- **MAP@k**: PrecisiÃ³n promedio
- **MRR@k**: Reciprocal rank del primer relevante

#### 4.3 Reranking con CrossEncoder
- Procesamiento conjunto [pregunta, documento] con atenciÃ³n cruzada
- Batch size adaptativo segÃºn longitud de contenido
- GeneraciÃ³n de scores de relevancia
- NormalizaciÃ³n Min-Max de scores â†’ [0, 1]
- Reordenamiento final de documentos

#### 4.4 MÃ©tricas POST-Reranking
Ciclo para k âˆˆ {1, 3, 5, 10, 15}:
- Mismas mÃ©tricas que PRE-reranking calculadas sobre lista reordenada
- MÃ©tricas adicionales: CrossEncoder Score promedio

### ğŸ¤– FASE 5: MÃ‰TRICAS RAG

#### 5.1 GeneraciÃ³n de Respuesta
- Uso de GPT-3.5-turbo con temperatura=0 (determinÃ­stico)
- Contexto: Top-3 documentos post-reranking
- Cache de respuestas para eficiencia

#### 5.2 RAGAS Metrics (API Call Ãšnica)
Single API call para 5 mÃ©tricas (escala 1-5 â†’ normalizaciÃ³n [0,1]):
- **Faithfulness**: Consistencia con contexto
- **Answer Relevancy**: Relevancia respecto a pregunta
- **Answer Correctness**: ComparaciÃ³n con ground truth
- **Context Precision**: PrecisiÃ³n del contexto recuperado
- **Context Recall**: Completitud del contexto

#### 5.3 BERTScore y Semantic Similarity
- **BERTScore** (DeBERTa-base-mnli):
  - Precision, Recall, F1 semÃ¡nticos
- **Semantic Similarity**:
  - Similitud coseno entre embeddings de respuesta y ground truth

### ğŸ’¾ FASE 6: PREPARACIÃ“N Y GUARDADO
- AgregaciÃ³n de mÃ©tricas por modelo
- CÃ¡lculo de promedios y estadÃ­sticas
- GeneraciÃ³n de timestamp (zona horaria Chile)
- Guardado en formato JSON compatible con Streamlit
- Resumen de resultados y estadÃ­sticas de cache

## Optimizaciones Implementadas

### ğŸ§  GPU Memory Management
- Limpieza cada 100 preguntas
- Batch size adaptativo segÃºn longitud de documentos
- LiberaciÃ³n explÃ­cita de variables

### ğŸ’¾ OpenAI API Cache
- Cache de respuestas por hash (pregunta + contexto)
- Hit rate tÃ­pico: ~100% en re-evaluaciones
- Ahorro estimado: $0.05 por query cacheada

### âš¡ Performance
- Single API call para RAGAS (6 calls â†’ 1, ahorro 83%)
- Modelo semÃ¡ntico cargado una sola vez (reutilizado 2,067 veces)
- Procesamiento por lotes con tamaÃ±os optimizados

## MÃ©tricas de Salida

### Por Modelo y Pregunta:
- **Pre-reranking**: 7 mÃ©tricas Ã— 5 valores de k = 35 mÃ©tricas
- **Post-reranking**: 8 mÃ©tricas Ã— 5 valores de k = 40 mÃ©tricas
- **RAG**: 9 mÃ©tricas (6 RAGAS + 3 BERTScore)
- **Total**: ~84 mÃ©tricas por pregunta por modelo

### Agregados por Modelo:
- Promedios de todas las mÃ©tricas
- EstadÃ­sticas de scores (coseno, CrossEncoder)
- Tasas de Ã©xito y disponibilidad
- Comparaciones pre/post reranking

## Formato de Salida

```json
{
  "config": {
    "num_questions": 2067,
    "models_evaluated": 4,
    "reranking_method": "crossencoder",
    "top_k": 15
  },
  "evaluation_info": {
    "timestamp": "2025-10-29T00:30:45-03:00",
    "timezone": "America/Santiago",
    "total_duration_seconds": 57.8,
    "data_verification": {
      "is_real_data": true,
      "rag_framework": "Complete_RAGAS_with_OpenAI_API"
    }
  },
  "results": {
    "ada": { /* mÃ©tricas completas */ },
    "e5-large": { /* mÃ©tricas completas */ },
    "mpnet": { /* mÃ©tricas completas */ },
    "minilm": { /* mÃ©tricas completas */ }
  }
}
```
