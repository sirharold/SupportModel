# RESUMEN

Esta investigación desarrolla y evalúa un sistema de recuperación semántica de información técnica especializada basado en arquitecturas RAG (Retrieval-Augmented Generation), utilizando documentación de Microsoft Azure como caso de estudio. El trabajo aborda el problema de accesibilidad del conocimiento técnico donde los sistemas de búsqueda léxica tradicionales presentan limitaciones significativas en dominios especializados. La investigación compara sistemáticamente cuatro modelos de embeddings —Ada (OpenAI), MPNet, E5-Large y MiniLM— evaluando su rendimiento en recuperación vectorial y tras aplicar reranking neural con CrossEncoder. El sistema almacena más de 800,000 vectores en ChromaDB, procesando un corpus de 187,031 chunks de documentación desde 62,417 documentos únicos de Microsoft Learn, utilizando 2,067 pares pregunta-documento validados como ground truth.

Los resultados establecen una jerarquía de rendimiento: Ada alcanza Precision@5 de 0.098, superando a MPNet (0.070), E5-Large (0.065) y MiniLM (0.053), con diferencias relativas de 28-46%. MPNet alcanza 71% del rendimiento de Ada utilizando solo 50% de dimensiones (768 vs 1,536), representando un trade-off favorable para aplicaciones con restricciones de recursos. El análisis de reranking revela un patrón diferencial robusto: CrossEncoder mejora modelos débiles (MiniLM +13.6%) pero degrada modelos optimizados (Ada -16.7%), estableciendo que la aplicación de reranking debe ser selectiva según el modelo de embedding utilizado.

La evaluación multi-métrica identifica una discrepancia crítica: mientras las métricas de recuperación tradicionales muestran valores bajos (Precision@5 < 0.10), las métricas semánticas revelan rendimiento superior (Faithfulness 0.69-0.73, BERTScore 0.54-0.62), sugiriendo que todos los modelos producen respuestas de calidad semántica comparable. Esta discrepancia evidencia la principal limitación metodológica: el ground truth basado en enlaces comunitarios no garantiza validez de la correspondencia entre preguntas y documentos, imposibilitando conclusiones sobre rendimiento absoluto aunque permitiendo comparaciones relativas válidas entre modelos.

Las contribuciones metodológicas incluyen la documentación sistemática de limitaciones en construcción automatizada de ground truth, un framework de evaluación multi-métrica combinando métricas tradicionales con RAGAS y BERTScore, y la validación del patrón de reranking diferencial. Las contribuciones técnicas comprenden una implementación de referencia para almacenamiento vectorial con ChromaDB (latencia < 100ms, 800,000+ vectores) y un pipeline automatizado de evaluación reproducible. El trabajo establece como recomendación principal el desarrollo de ground truth validado por expertos del dominio técnico, con extensiones recomendadas en búsqueda híbrida, procesamiento multi-modal, y validación cross-domain en otros ecosistemas cloud (AWS, GCP).

**Palabras clave:** Recuperación de Información Semántica, RAG, Embeddings, Reranking Neural, Soporte Técnico, ChromaDB, RAGAS, BERTScore, Microsoft Azure
